{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3748acd-0fa5-4606-b48d-324ef5a14571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "=== Training RealNet (baseline) ===\n",
      "[RealNet] Epoch 1 | loss=1.6356 | test_acc=0.4718 | elapsed=1.95s\n",
      "[RealNet] Epoch 2 | loss=1.4325 | test_acc=0.4929 | elapsed=3.91s\n",
      "[RealNet] Epoch 3 | loss=1.3499 | test_acc=0.4987 | elapsed=5.88s\n",
      "[RealNet] Epoch 4 | loss=1.2790 | test_acc=0.5054 | elapsed=7.85s\n",
      "[RealNet] Epoch 5 | loss=1.2232 | test_acc=0.5185 | elapsed=9.80s\n",
      "RealNet final: acc=0.5185, time=9.80s\n",
      "\n",
      "=== Training RealNetLarge (large capacity) ===\n",
      "[RealNetLarge] Epoch 1 | loss=1.6478 | test_acc=0.4690 | elapsed=1.91s\n",
      "[RealNetLarge] Epoch 2 | loss=1.4409 | test_acc=0.4873 | elapsed=3.83s\n",
      "[RealNetLarge] Epoch 3 | loss=1.3512 | test_acc=0.5104 | elapsed=5.76s\n",
      "[RealNetLarge] Epoch 4 | loss=1.2718 | test_acc=0.5122 | elapsed=7.75s\n",
      "[RealNetLarge] Epoch 5 | loss=1.2148 | test_acc=0.5152 | elapsed=9.75s\n",
      "RealNetLarge final: acc=0.5152, time=9.75s\n",
      "\n",
      "=== Training QuatNet_4pix (4 pixels per quaternion) ===\n",
      "[QuatNet_4pix] Epoch 1 | loss=1.7822 | test_acc=0.4222 | elapsed=9.22s\n",
      "[QuatNet_4pix] Epoch 2 | loss=1.6247 | test_acc=0.4445 | elapsed=17.69s\n",
      "[QuatNet_4pix] Epoch 3 | loss=1.5390 | test_acc=0.4520 | elapsed=25.92s\n",
      "[QuatNet_4pix] Epoch 4 | loss=1.4680 | test_acc=0.4629 | elapsed=34.30s\n",
      "[QuatNet_4pix] Epoch 5 | loss=1.4058 | test_acc=0.4663 | elapsed=43.42s\n",
      "QuatNet_4pix final: acc=0.4663, time=43.42s\n",
      "\n",
      "=== Training QuatNet_RGB (1 quaternion per pixel, RGB structure) ===\n",
      "[QuatNet_RGB] Epoch 1 | loss=1.7675 | test_acc=0.4296 | elapsed=11.33s\n",
      "[QuatNet_RGB] Epoch 2 | loss=1.5812 | test_acc=0.4296 | elapsed=22.54s\n",
      "[QuatNet_RGB] Epoch 3 | loss=1.5101 | test_acc=0.4524 | elapsed=34.61s\n",
      "[QuatNet_RGB] Epoch 4 | loss=1.4553 | test_acc=0.4764 | elapsed=45.81s\n",
      "[QuatNet_RGB] Epoch 5 | loss=1.4103 | test_acc=0.4641 | elapsed=57.24s\n",
      "QuatNet_RGB final: acc=0.4641, time=57.24s\n",
      "\n",
      "=== Parameter Counts ===\n",
      "RealNet:        789,258 parameters\n",
      "RealNetLarge:   1,578,506 parameters\n",
      "QuatNet_4pix:   797,706 parameters\n",
      "QuatNet_RGB:    1,059,850 parameters\n",
      "\n",
      "=== Summary (CIFAR-10, seed=42, 5 epochs) ===\n",
      "RealNet:        acc=0.5185, time=9.80s\n",
      "RealNetLarge:   acc=0.5152, time=9.75s\n",
      "QuatNet_4pix:   acc=0.4663, time=43.42s\n",
      "QuatNet_RGB:    acc=0.4641, time=57.24s\n",
      "\n",
      "=== Comparative Analysis ===\n",
      "\n",
      "QuatNet_4pix vs RealNet:\n",
      "  Accuracy: 0.4663 vs 0.5185 (+5.22 points)\n",
      "  Time: 43.42s vs 9.80s (4.43x)\n",
      "  Parameters: 797,706 vs 789,258 (1.01x)\n",
      "\n",
      "QuatNet_RGB vs RealNet:\n",
      "  Accuracy: 0.4641 vs 0.5185 (+5.44 points)\n",
      "  Time: 57.24s vs 9.80s (5.84x)\n",
      "  Parameters: 1,059,850 vs 789,258 (1.34x)\n",
      "\n",
      "QuatNet_RGB vs RealNetLarge:\n",
      "  Accuracy: 0.4641 vs 0.5152 (+5.11 points)\n",
      "  Time: 57.24s vs 9.75s (5.87x)\n",
      "  Parameters: 1,059,850 vs 1,578,506 (0.67x)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ============================================\n",
    "# Quaternion utilities (PyTorch tensors)\n",
    "# Quaternions are stored as (..., 4): (w, x, y, z)\n",
    "# ============================================\n",
    "\n",
    "def q_normalize(q):\n",
    "    norm = torch.linalg.norm(q, dim=-1, keepdim=True) + 1e-8\n",
    "    return q / norm\n",
    "\n",
    "def q_conj(q):\n",
    "    w, x, y, z = torch.unbind(q, dim=-1)\n",
    "    return torch.stack([w, -x, -y, -z], dim=-1)\n",
    "\n",
    "def q_mul(a, b):\n",
    "    \"\"\"Hamilton product of two quaternions.\n",
    "    a, b: (..., 4)\"\"\"\n",
    "    aw, ax, ay, az = torch.unbind(a, dim=-1)\n",
    "    bw, bx, by, bz = torch.unbind(b, dim=-1)\n",
    "\n",
    "    w = aw * bw - ax * bx - ay * by - az * bz\n",
    "    x = aw * bx + ax * bw + ay * bz - az * by\n",
    "    y = aw * by - ax * bz + ay * bw + az * bx\n",
    "    z = aw * bz + ax * by - ay * bx + az * bw\n",
    "\n",
    "    return torch.stack([w, x, y, z], dim=-1)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Real-valued baseline network\n",
    "# ============================================\n",
    "\n",
    "class RealNet(nn.Module):\n",
    "    def __init__(self, input_dim=3072, hidden_dim=256, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RealNet_Large(nn.Module):\n",
    "    def __init__(self, input_dim=3072, hidden_dim=512, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Quaternion Linear Layer and Quaternion Nets\n",
    "# ============================================\n",
    "\n",
    "class QuaternionLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features, 4))\n",
    "        self.bias = nn.Parameter(torch.empty(out_features, 4))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.weight, mean=0.0, std=0.1)\n",
    "        with torch.no_grad():\n",
    "            self.weight[:] = q_normalize(self.weight)\n",
    "            nn.init.constant_(self.bias[..., 0], 1.0)\n",
    "            nn.init.constant_(self.bias[..., 1:], 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        w = self.weight.unsqueeze(0)\n",
    "        x_exp = x.unsqueeze(1)\n",
    "        prod = q_mul(w, x_exp)\n",
    "        out = prod.sum(dim=2) + self.bias\n",
    "        return out\n",
    "\n",
    "\n",
    "class QuatNet_4pix(nn.Module):\n",
    "    \"\"\"Quaternion network: 4 pixels per quaternion (768 quaternions)\"\"\"\n",
    "    def __init__(self, num_quats=768, hidden_quat=256, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.num_quats = num_quats\n",
    "        \n",
    "        self.quat_fc1 = QuaternionLinear(num_quats, hidden_quat)\n",
    "        self.fc2 = nn.Linear(hidden_quat * 4, num_classes)\n",
    "    \n",
    "    def image_to_quats(self, x):\n",
    "        # x: (B, 3, 32, 32) -> (B, 768, 4)\n",
    "        # Group every 4 pixels into a quaternion\n",
    "        B = x.size(0)\n",
    "        flat = x.view(B, -1)  # (B, 3072)\n",
    "        quats = flat.view(B, self.num_quats, 4)  # (B, 768, 4)\n",
    "        return quats\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        q_in = self.image_to_quats(x)\n",
    "        hq = self.quat_fc1(q_in)\n",
    "        hq = q_normalize(hq)\n",
    "        hq = torch.tanh(hq)\n",
    "        h_flat = hq.view(B, -1)\n",
    "        logits = self.fc2(h_flat)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class QuatNet_RGB(nn.Module):\n",
    "    \"\"\"Quaternion network: 1 quaternion per pixel using (R,G,B,1) structure (1024 quaternions)\"\"\"\n",
    "    def __init__(self, num_pixels=1024, hidden_quat=256, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.num_pixels = num_pixels\n",
    "        \n",
    "        self.quat_fc1 = QuaternionLinear(num_pixels, hidden_quat)\n",
    "        self.fc2 = nn.Linear(hidden_quat * 4, num_classes)\n",
    "    \n",
    "    def image_to_quats(self, x):\n",
    "        # x: (B, 3, 32, 32) -> (B, 1024, 4) where each quaternion is (R,G,B,1)\n",
    "        B = x.size(0)\n",
    "        x = x.permute(0, 2, 3, 1)  # (B, 32, 32, 3)\n",
    "        x = x.reshape(B, self.num_pixels, 3)  # (B, 1024, 3)\n",
    "        ones = torch.ones(B, self.num_pixels, 1, device=x.device)\n",
    "        quats = torch.cat([x, ones], dim=-1)  # (B, 1024, 4)\n",
    "        return quats\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        q_in = self.image_to_quats(x)\n",
    "        hq = self.quat_fc1(q_in)\n",
    "        hq = q_normalize(hq)\n",
    "        hq = torch.tanh(hq)\n",
    "        h_flat = hq.view(B, -1)\n",
    "        logits = self.fc2(h_flat)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Training / evaluation helpers\n",
    "# ============================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Main experiment: RealNet vs QuatNets\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    # Set seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # CIFAR-10 with normalization\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_ds  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # ---------------- RealNet ----------------\n",
    "    real_net = RealNet(input_dim=3072, hidden_dim=256).to(device)\n",
    "    real_opt = torch.optim.Adam(real_net.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"\\n=== Training RealNet (baseline) ===\")\n",
    "    start = time.time()\n",
    "    for epoch in range(1, 6):\n",
    "        loss = train_one_epoch(real_net, train_loader, real_opt, device)\n",
    "        acc = evaluate(real_net, test_loader, device)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"[RealNet] Epoch {epoch} | loss={loss:.4f} | test_acc={acc:.4f} | elapsed={elapsed:.2f}s\")\n",
    "    real_time = time.time() - start\n",
    "    real_acc = evaluate(real_net, test_loader, device)\n",
    "    print(f\"RealNet final: acc={real_acc:.4f}, time={real_time:.2f}s\")\n",
    "\n",
    "    # ---------------- RealNetLarge ----------------\n",
    "    realnet_large = RealNet_Large(input_dim=3072, hidden_dim=512).to(device)\n",
    "    reallarge_opt = torch.optim.Adam(realnet_large.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"\\n=== Training RealNetLarge (large capacity) ===\")\n",
    "    start = time.time()\n",
    "    for epoch in range(1, 6):\n",
    "        loss = train_one_epoch(realnet_large, train_loader, reallarge_opt, device)\n",
    "        acc = evaluate(realnet_large, test_loader, device)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"[RealNetLarge] Epoch {epoch} | loss={loss:.4f} | test_acc={acc:.4f} | elapsed={elapsed:.2f}s\")\n",
    "    reallarge_time = time.time() - start\n",
    "    reallarge_acc = evaluate(realnet_large, test_loader, device)\n",
    "    print(f\"RealNetLarge final: acc={reallarge_acc:.4f}, time={reallarge_time:.2f}s\")\n",
    "\n",
    "    # ---------------- QuatNet_4pix ----------------\n",
    "    quat_net_4pix = QuatNet_4pix(num_quats=768, hidden_quat=256).to(device)\n",
    "    quat_4pix_opt = torch.optim.Adam(quat_net_4pix.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"\\n=== Training QuatNet_4pix (4 pixels per quaternion) ===\")\n",
    "    start = time.time()\n",
    "    for epoch in range(1, 6):\n",
    "        loss = train_one_epoch(quat_net_4pix, train_loader, quat_4pix_opt, device)\n",
    "        acc = evaluate(quat_net_4pix, test_loader, device)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"[QuatNet_4pix] Epoch {epoch} | loss={loss:.4f} | test_acc={acc:.4f} | elapsed={elapsed:.2f}s\")\n",
    "    quat_4pix_time = time.time() - start\n",
    "    quat_4pix_acc = evaluate(quat_net_4pix, test_loader, device)\n",
    "    print(f\"QuatNet_4pix final: acc={quat_4pix_acc:.4f}, time={quat_4pix_time:.2f}s\")\n",
    "\n",
    "    # ---------------- QuatNet_RGB ----------------\n",
    "    quat_net_rgb = QuatNet_RGB(num_pixels=1024, hidden_quat=256).to(device)\n",
    "    quat_rgb_opt = torch.optim.Adam(quat_net_rgb.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"\\n=== Training QuatNet_RGB (1 quaternion per pixel, RGB structure) ===\")\n",
    "    start = time.time()\n",
    "    for epoch in range(1, 6):\n",
    "        loss = train_one_epoch(quat_net_rgb, train_loader, quat_rgb_opt, device)\n",
    "        acc = evaluate(quat_net_rgb, test_loader, device)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"[QuatNet_RGB] Epoch {epoch} | loss={loss:.4f} | test_acc={acc:.4f} | elapsed={elapsed:.2f}s\")\n",
    "    quat_rgb_time = time.time() - start\n",
    "    quat_rgb_acc = evaluate(quat_net_rgb, test_loader, device)\n",
    "    print(f\"QuatNet_RGB final: acc={quat_rgb_acc:.4f}, time={quat_rgb_time:.2f}s\")\n",
    "\n",
    "    # ---------------- Summary ----------------\n",
    "    print(\"\\n=== Parameter Counts ===\")\n",
    "    real_params = sum(p.numel() for p in real_net.parameters())\n",
    "    reallarge_params = sum(p.numel() for p in realnet_large.parameters())\n",
    "    quat_4pix_params = sum(p.numel() for p in quat_net_4pix.parameters())\n",
    "    quat_rgb_params = sum(p.numel() for p in quat_net_rgb.parameters())\n",
    "    print(f\"RealNet:        {real_params:,} parameters\")\n",
    "    print(f\"RealNetLarge:   {reallarge_params:,} parameters\")\n",
    "    print(f\"QuatNet_4pix:   {quat_4pix_params:,} parameters\")\n",
    "    print(f\"QuatNet_RGB:    {quat_rgb_params:,} parameters\")\n",
    "    \n",
    "    print(\"\\n=== Summary (CIFAR-10, seed=42, 5 epochs) ===\")\n",
    "    print(f\"RealNet:        acc={real_acc:.4f}, time={real_time:.2f}s\")\n",
    "    print(f\"RealNetLarge:   acc={reallarge_acc:.4f}, time={reallarge_time:.2f}s\")\n",
    "    print(f\"QuatNet_4pix:   acc={quat_4pix_acc:.4f}, time={quat_4pix_time:.2f}s\")\n",
    "    print(f\"QuatNet_RGB:    acc={quat_rgb_acc:.4f}, time={quat_rgb_time:.2f}s\")\n",
    "    \n",
    "    print(\"\\n=== Comparative Analysis ===\")\n",
    "    print(\"\\nQuatNet_4pix vs RealNet:\")\n",
    "    print(f\"  Accuracy: {quat_4pix_acc:.4f} vs {real_acc:.4f} ({(real_acc - quat_4pix_acc)*100:+.2f} points)\")\n",
    "    print(f\"  Time: {quat_4pix_time:.2f}s vs {real_time:.2f}s ({quat_4pix_time/real_time:.2f}x)\")\n",
    "    print(f\"  Parameters: {quat_4pix_params:,} vs {real_params:,} ({quat_4pix_params/real_params:.2f}x)\")\n",
    "    \n",
    "    print(\"\\nQuatNet_RGB vs RealNet:\")\n",
    "    print(f\"  Accuracy: {quat_rgb_acc:.4f} vs {real_acc:.4f} ({(real_acc - quat_rgb_acc)*100:+.2f} points)\")\n",
    "    print(f\"  Time: {quat_rgb_time:.2f}s vs {real_time:.2f}s ({quat_rgb_time/real_time:.2f}x)\")\n",
    "    print(f\"  Parameters: {quat_rgb_params:,} vs {real_params:,} ({quat_rgb_params/real_params:.2f}x)\")\n",
    "    \n",
    "    print(\"\\nQuatNet_RGB vs RealNetLarge:\")\n",
    "    print(f\"  Accuracy: {quat_rgb_acc:.4f} vs {reallarge_acc:.4f} ({(reallarge_acc - quat_rgb_acc)*100:+.2f} points)\")\n",
    "    print(f\"  Time: {quat_rgb_time:.2f}s vs {reallarge_time:.2f}s ({quat_rgb_time/reallarge_time:.2f}x)\")\n",
    "    print(f\"  Parameters: {quat_rgb_params:,} vs {reallarge_params:,} ({quat_rgb_params/reallarge_params:.2f}x)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59708f5-2b12-458e-82ab-94dd5b2a6ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-env)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
