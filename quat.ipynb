{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab2c842-cd21-4718-8262-2b7af6e80215",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe954c1-3fc9-4b0f-b299-d5f283659426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using lightning.gpu device (requires: pip install pennylane-lightning-gpu)\n",
      "Using PyTorch device: cpu\n",
      "======================================================================\n",
      "CLEAN SU(2) COMPARISON: Real vs Quaternion vs Quantum (LIGHTNING)\n",
      "======================================================================\n",
      "\n",
      "Experimental Design:\n",
      "  • Dataset: MNIST (28×28 grayscale)\n",
      "  • Stratified sampling: 15K train (1,500/class), 3K test (300/class)\n",
      "    - Rationale: Models have ~10-15K parameters; 60K samples unnecessary\n",
      "    - Enables 4-6x faster quantum training while maintaining valid comparison\n",
      "    - All models train on identical stratified samples\n",
      "  • Shared preprocessor: 784 → 16 features\n",
      "    - Trained with RealNet, then frozen\n",
      "    - Reused (frozen) for Quat and Quantum heads\n",
      "  • Heads on identical 16-D frozen features:\n",
      "    - Real head: 16 → 64 → 10 (standard MLP)\n",
      "    - Quaternion head: 4 quats → 16 quats → 10 quats → 10\n",
      "    - Quantum head (no ent): 4 qubits, 3 layers → 10\n",
      "    - Quantum head (entangled): 4 qubits, 3 layers + CNOT ring → 10\n",
      "\n",
      "Quantum device: lightning.gpu\n",
      "  Expected quantum training time: ~30-45 min per seed\n",
      "======================================================================\n",
      "\n",
      "Creating stratified samples...\n",
      "  Train samples: 15000 (stratified, 1500 per class)\n",
      "  Test samples:  3000 (stratified, 300 per class)\n",
      "\n",
      "======================================================================\n",
      "SEED 42\n",
      "======================================================================\n",
      "\n",
      "  Training RealNet (seed=42)...\n",
      "  [Real] Epoch  1 | loss=1.2935 | test_acc=0.8660 | time=1.1s\n",
      "  [Real] Epoch  2 | loss=0.4181 | test_acc=0.9000 | time=2.1s\n",
      "  [Real] Epoch  3 | loss=0.3083 | test_acc=0.9113 | time=3.0s\n",
      "  [Real] Epoch  4 | loss=0.2630 | test_acc=0.9167 | time=4.0s\n",
      "  [Real] Epoch  5 | loss=0.2338 | test_acc=0.9213 | time=5.0s\n",
      "  [Real] Epoch  6 | loss=0.2149 | test_acc=0.9240 | time=6.0s\n",
      "  [Real] Epoch  7 | loss=0.1929 | test_acc=0.9227 | time=7.0s\n",
      "  [Real] Epoch  8 | loss=0.1809 | test_acc=0.9247 | time=7.9s\n",
      "  [Real] Epoch  9 | loss=0.1671 | test_acc=0.9303 | time=8.9s\n",
      "  [Real] Epoch 10 | loss=0.1558 | test_acc=0.9320 | time=9.9s\n",
      "  [Real] Epoch 11 | loss=0.1486 | test_acc=0.9320 | time=10.9s\n",
      "  [Real] Epoch 12 | loss=0.1392 | test_acc=0.9317 | time=11.9s\n",
      "  [Real] Epoch 13 | loss=0.1311 | test_acc=0.9320 | time=12.8s\n",
      "  [Real] Epoch 14 | loss=0.1222 | test_acc=0.9317 | time=13.8s\n",
      "  [Real] Epoch 15 | loss=0.1156 | test_acc=0.9347 | time=14.9s\n",
      "  [Real] Epoch 16 | loss=0.1075 | test_acc=0.9327 | time=15.9s\n",
      "  [Real] Epoch 17 | loss=0.1084 | test_acc=0.9353 | time=16.9s\n",
      "  [Real] Epoch 18 | loss=0.0954 | test_acc=0.9363 | time=17.9s\n",
      "  [Real] Epoch 19 | loss=0.0910 | test_acc=0.9343 | time=18.8s\n",
      "  [Real] Epoch 20 | loss=0.0926 | test_acc=0.9353 | time=19.8s\n",
      "  [Real] Epoch 21 | loss=0.0838 | test_acc=0.9290 | time=20.9s\n",
      "  [Real] Epoch 22 | loss=0.0764 | test_acc=0.9347 | time=21.9s\n",
      "  [Real] Epoch 23 | loss=0.0718 | test_acc=0.9343 | time=22.8s\n",
      "  [Real] Epoch 24 | loss=0.0679 | test_acc=0.9357 | time=23.8s\n",
      "  [Real] Epoch 25 | loss=0.0653 | test_acc=0.9340 | time=24.9s\n",
      "  [Real] Epoch 26 | loss=0.0636 | test_acc=0.9347 | time=25.9s\n",
      "  [Real] Early stop at epoch 26 (no improvement for 8 epochs)\n",
      "\n",
      "  → Preprocessor frozen with 12560 params\n",
      "\n",
      "  Training QuatNet with frozen preprocessor (seed=42)...\n",
      "  [Quat] Epoch  1 | loss=2.2760 | test_acc=0.6200 | time=1.1s\n",
      "  [Quat] Epoch  2 | loss=0.9132 | test_acc=0.8340 | time=2.3s\n",
      "  [Quat] Epoch  3 | loss=0.5085 | test_acc=0.8873 | time=3.5s\n",
      "  [Quat] Epoch  4 | loss=0.3548 | test_acc=0.9063 | time=4.6s\n",
      "  [Quat] Epoch  5 | loss=0.2790 | test_acc=0.9143 | time=5.8s\n",
      "  [Quat] Epoch  6 | loss=0.2342 | test_acc=0.9197 | time=7.0s\n",
      "  [Quat] Epoch  7 | loss=0.2045 | test_acc=0.9227 | time=8.2s\n",
      "  [Quat] Epoch  8 | loss=0.1831 | test_acc=0.9230 | time=9.4s\n",
      "  [Quat] Epoch  9 | loss=0.1670 | test_acc=0.9247 | time=10.7s\n",
      "  [Quat] Epoch 10 | loss=0.1542 | test_acc=0.9260 | time=11.8s\n",
      "  [Quat] Epoch 11 | loss=0.1439 | test_acc=0.9267 | time=13.0s\n",
      "  [Quat] Epoch 12 | loss=0.1353 | test_acc=0.9283 | time=14.2s\n",
      "  [Quat] Epoch 13 | loss=0.1280 | test_acc=0.9280 | time=15.4s\n",
      "  [Quat] Epoch 14 | loss=0.1218 | test_acc=0.9297 | time=16.6s\n",
      "  [Quat] Epoch 15 | loss=0.1163 | test_acc=0.9297 | time=17.8s\n",
      "  [Quat] Epoch 16 | loss=0.1116 | test_acc=0.9283 | time=18.9s\n",
      "  [Quat] Epoch 17 | loss=0.1071 | test_acc=0.9293 | time=20.0s\n",
      "  [Quat] Epoch 18 | loss=0.1033 | test_acc=0.9290 | time=21.1s\n",
      "  [Quat] Epoch 19 | loss=0.0999 | test_acc=0.9300 | time=22.3s\n",
      "  [Quat] Epoch 20 | loss=0.0967 | test_acc=0.9303 | time=23.3s\n",
      "  [Quat] Epoch 21 | loss=0.0938 | test_acc=0.9307 | time=24.4s\n",
      "  [Quat] Epoch 22 | loss=0.0913 | test_acc=0.9303 | time=25.6s\n",
      "  [Quat] Epoch 23 | loss=0.0889 | test_acc=0.9310 | time=26.7s\n",
      "  [Quat] Epoch 24 | loss=0.0867 | test_acc=0.9303 | time=27.8s\n",
      "  [Quat] Epoch 25 | loss=0.0847 | test_acc=0.9313 | time=29.0s\n",
      "  [Quat] Epoch 26 | loss=0.0828 | test_acc=0.9297 | time=30.2s\n",
      "  [Quat] Epoch 27 | loss=0.0811 | test_acc=0.9297 | time=31.3s\n",
      "  [Quat] Epoch 28 | loss=0.0795 | test_acc=0.9307 | time=32.5s\n",
      "  [Quat] Epoch 29 | loss=0.0780 | test_acc=0.9317 | time=33.6s\n",
      "  [Quat] Epoch 30 | loss=0.0768 | test_acc=0.9307 | time=34.8s\n",
      "  [Quat] Epoch 31 | loss=0.0754 | test_acc=0.9317 | time=35.9s\n",
      "  [Quat] Epoch 32 | loss=0.0741 | test_acc=0.9313 | time=37.0s\n",
      "  [Quat] Epoch 33 | loss=0.0731 | test_acc=0.9317 | time=38.1s\n",
      "  [Quat] Epoch 34 | loss=0.0720 | test_acc=0.9323 | time=39.3s\n",
      "  [Quat] Epoch 35 | loss=0.0710 | test_acc=0.9323 | time=40.6s\n",
      "  [Quat] Epoch 36 | loss=0.0699 | test_acc=0.9330 | time=41.8s\n",
      "  [Quat] Epoch 37 | loss=0.0691 | test_acc=0.9323 | time=42.9s\n",
      "  [Quat] Epoch 38 | loss=0.0683 | test_acc=0.9313 | time=44.0s\n",
      "  [Quat] Epoch 39 | loss=0.0677 | test_acc=0.9317 | time=45.2s\n",
      "  [Quat] Epoch 40 | loss=0.0667 | test_acc=0.9330 | time=46.3s\n",
      "\n",
      "  Training QuantumNet (NO entanglement, seed=42, lightning.gpu)...\n",
      "  [QuantumNoEnt] Epoch 1/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  1 | loss=1.7303 | test_acc=0.7287 | time=490.5s\n",
      "  [QuantumNoEnt] Epoch 2/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  2 | loss=0.9788 | test_acc=0.8210 | time=985.8s\n",
      "  [QuantumNoEnt] Epoch 3/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  3 | loss=0.6780 | test_acc=0.8523 | time=1486.8s\n",
      "  [QuantumNoEnt] Epoch 4/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  4 | loss=0.5489 | test_acc=0.8573 | time=1984.4s\n",
      "  [QuantumNoEnt] Epoch 5/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  5 | loss=0.4877 | test_acc=0.8587 | time=2490.0s\n",
      "  [QuantumNoEnt] Epoch 6/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  6 | loss=0.4531 | test_acc=0.8633 | time=2959.3s\n",
      "  [QuantumNoEnt] Epoch 7/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  7 | loss=0.4305 | test_acc=0.8623 | time=3420.8s\n",
      "  [QuantumNoEnt] Epoch 8/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  8 | loss=0.4130 | test_acc=0.8623 | time=3890.8s\n",
      "  [QuantumNoEnt] Epoch 9/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  9 | loss=0.3997 | test_acc=0.8663 | time=4357.6s\n",
      "  [QuantumNoEnt] Epoch 10/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 10 | loss=0.3884 | test_acc=0.8660 | time=4831.8s\n",
      "  [QuantumNoEnt] Epoch 11/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 11 | loss=0.3783 | test_acc=0.8710 | time=5302.4s\n",
      "  [QuantumNoEnt] Epoch 12/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 12 | loss=0.3704 | test_acc=0.8700 | time=5785.3s\n",
      "  [QuantumNoEnt] Epoch 13/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 13 | loss=0.3639 | test_acc=0.8700 | time=6272.8s\n",
      "  [QuantumNoEnt] Epoch 14/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 14 | loss=0.3583 | test_acc=0.8693 | time=6754.2s\n",
      "  [QuantumNoEnt] Epoch 15/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 15 | loss=0.3532 | test_acc=0.8697 | time=7241.1s\n",
      "  [QuantumNoEnt] Epoch 16/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 16 | loss=0.3487 | test_acc=0.8670 | time=7722.1s\n",
      "  [QuantumNoEnt] Epoch 17/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 17 | loss=0.3456 | test_acc=0.8673 | time=8215.2s\n",
      "  [QuantumNoEnt] Epoch 18/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 18 | loss=0.3425 | test_acc=0.8707 | time=8695.2s\n",
      "  [QuantumNoEnt] Epoch 19/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 19 | loss=0.3403 | test_acc=0.8710 | time=9175.3s\n",
      "  [QuantumNoEnt] Epoch 20/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 20 | loss=0.3369 | test_acc=0.8710 | time=9647.3s\n",
      "  [QuantumNoEnt] Epoch 21/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 21 | loss=0.3355 | test_acc=0.8743 | time=10125.7s\n",
      "  [QuantumNoEnt] Epoch 22/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 22 | loss=0.3338 | test_acc=0.8690 | time=10601.4s\n",
      "  [QuantumNoEnt] Epoch 23/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 23 | loss=0.3316 | test_acc=0.8710 | time=11078.0s\n",
      "  [QuantumNoEnt] Epoch 24/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 24 | loss=0.3303 | test_acc=0.8703 | time=11569.0s\n",
      "  [QuantumNoEnt] Epoch 25/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 25 | loss=0.3295 | test_acc=0.8720 | time=12039.0s\n",
      "  [QuantumNoEnt] Epoch 26/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 26 | loss=0.3273 | test_acc=0.8697 | time=12518.9s\n",
      "  [QuantumNoEnt] Epoch 27/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 27 | loss=0.3262 | test_acc=0.8680 | time=12989.8s\n",
      "  [QuantumNoEnt] Epoch 28/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 28 | loss=0.3249 | test_acc=0.8677 | time=13460.1s\n",
      "  [QuantumNoEnt] Epoch 29/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 29 | loss=0.3236 | test_acc=0.8713 | time=13936.1s\n",
      "  [QuantumNoEnt] Epoch 30/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 30 | loss=0.3221 | test_acc=0.8703 | time=14428.8s\n",
      "  [QuantumNoEnt] Epoch 31/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 31 | loss=0.3223 | test_acc=0.8723 | time=14912.7s\n",
      "  [QuantumNoEnt] Epoch 32/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 32 | loss=0.3205 | test_acc=0.8710 | time=15414.1s\n",
      "  [QuantumNoEnt] Epoch 33/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 33 | loss=0.3196 | test_acc=0.8697 | time=15901.8s\n",
      "  [QuantumNoEnt] Epoch 34/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 34 | loss=0.3189 | test_acc=0.8720 | time=16389.8s\n",
      "  [QuantumNoEnt] Epoch 35/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 35 | loss=0.3175 | test_acc=0.8710 | time=16897.7s\n",
      "  [QuantumNoEnt] Epoch 36/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 36 | loss=0.3174 | test_acc=0.8707 | time=17388.5s\n",
      "  [QuantumNoEnt] Epoch 37/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 37 | loss=0.3168 | test_acc=0.8710 | time=17879.8s\n",
      "  [QuantumNoEnt] Epoch 38/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 38 | loss=0.3156 | test_acc=0.8723 | time=18367.1s\n",
      "  [QuantumNoEnt] Epoch 39/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 39 | loss=0.3149 | test_acc=0.8733 | time=18837.5s\n",
      "  [QuantumNoEnt] Epoch 40/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 40 | loss=0.3143 | test_acc=0.8707 | time=19308.3s\n",
      "  [QuantumNoEnt] Epoch 41/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 41 | loss=0.3147 | test_acc=0.8723 | time=19800.5s\n",
      "  [QuantumNoEnt] Early stop at epoch 41 (no improvement for 20 epochs)\n",
      "\n",
      "  Training QuantumNet (WITH entanglement, seed=42, lightning.gpu)...\n",
      "  [QuantumEnt] Epoch 1/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  1 | loss=1.9565 | test_acc=0.4440 | time=537.0s\n",
      "  [QuantumEnt] Epoch 2/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  2 | loss=1.4564 | test_acc=0.5450 | time=1080.9s\n",
      "  [QuantumEnt] Epoch 3/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  3 | loss=1.2670 | test_acc=0.6057 | time=1622.0s\n",
      "  [QuantumEnt] Epoch 4/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  4 | loss=1.1410 | test_acc=0.6717 | time=2169.0s\n",
      "  [QuantumEnt] Epoch 5/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  5 | loss=1.0340 | test_acc=0.7100 | time=2699.7s\n",
      "  [QuantumEnt] Epoch 6/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  6 | loss=0.9469 | test_acc=0.7617 | time=3247.9s\n",
      "  [QuantumEnt] Epoch 7/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  7 | loss=0.8763 | test_acc=0.7927 | time=3790.1s\n",
      "  [QuantumEnt] Epoch 8/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  8 | loss=0.8129 | test_acc=0.8133 | time=4344.1s\n",
      "  [QuantumEnt] Epoch 9/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  9 | loss=0.7540 | test_acc=0.8347 | time=4879.4s\n",
      "  [QuantumEnt] Epoch 10/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 10 | loss=0.7001 | test_acc=0.8420 | time=5430.5s\n",
      "  [QuantumEnt] Epoch 11/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 11 | loss=0.6515 | test_acc=0.8487 | time=5970.0s\n",
      "  [QuantumEnt] Epoch 12/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 12 | loss=0.6085 | test_acc=0.8493 | time=6507.0s\n",
      "  [QuantumEnt] Epoch 13/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 13 | loss=0.5724 | test_acc=0.8477 | time=7028.5s\n",
      "  [QuantumEnt] Epoch 14/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 14 | loss=0.5421 | test_acc=0.8483 | time=7561.3s\n",
      "  [QuantumEnt] Epoch 15/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 15 | loss=0.5165 | test_acc=0.8513 | time=8096.1s\n",
      "  [QuantumEnt] Epoch 16/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 16 | loss=0.4949 | test_acc=0.8567 | time=8651.9s\n",
      "  [QuantumEnt] Epoch 17/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 17 | loss=0.4767 | test_acc=0.8520 | time=9199.2s\n",
      "  [QuantumEnt] Epoch 18/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 18 | loss=0.4617 | test_acc=0.8593 | time=9763.8s\n",
      "  [QuantumEnt] Epoch 19/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 19 | loss=0.4488 | test_acc=0.8563 | time=10323.0s\n",
      "  [QuantumEnt] Epoch 20/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 20 | loss=0.4377 | test_acc=0.8613 | time=10868.6s\n",
      "  [QuantumEnt] Epoch 21/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 21 | loss=0.4276 | test_acc=0.8610 | time=11407.9s\n",
      "  [QuantumEnt] Epoch 22/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 22 | loss=0.4190 | test_acc=0.8610 | time=11955.2s\n",
      "  [QuantumEnt] Epoch 23/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 23 | loss=0.4117 | test_acc=0.8623 | time=12494.4s\n",
      "  [QuantumEnt] Epoch 24/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 24 | loss=0.4048 | test_acc=0.8650 | time=13036.7s\n",
      "  [QuantumEnt] Epoch 25/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 25 | loss=0.3984 | test_acc=0.8633 | time=13579.7s\n",
      "  [QuantumEnt] Epoch 26/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 26 | loss=0.3927 | test_acc=0.8687 | time=14123.1s\n",
      "  [QuantumEnt] Epoch 27/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 27 | loss=0.3874 | test_acc=0.8667 | time=14660.0s\n",
      "  [QuantumEnt] Epoch 28/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 28 | loss=0.3833 | test_acc=0.8723 | time=15195.1s\n",
      "  [QuantumEnt] Epoch 29/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 29 | loss=0.3790 | test_acc=0.8740 | time=15727.8s\n",
      "  [QuantumEnt] Epoch 30/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 30 | loss=0.3746 | test_acc=0.8727 | time=16260.1s\n",
      "  [QuantumEnt] Epoch 31/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 31 | loss=0.3719 | test_acc=0.8747 | time=16793.5s\n",
      "  [QuantumEnt] Epoch 32/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 32 | loss=0.3681 | test_acc=0.8720 | time=17332.0s\n",
      "  [QuantumEnt] Epoch 33/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 33 | loss=0.3659 | test_acc=0.8767 | time=17870.2s\n",
      "  [QuantumEnt] Epoch 34/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 34 | loss=0.3622 | test_acc=0.8797 | time=18416.7s\n",
      "  [QuantumEnt] Epoch 35/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 35 | loss=0.3598 | test_acc=0.8777 | time=18934.2s\n",
      "  [QuantumEnt] Epoch 36/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 36 | loss=0.3569 | test_acc=0.8800 | time=19465.1s\n",
      "  [QuantumEnt] Epoch 37/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 37 | loss=0.3542 | test_acc=0.8797 | time=20007.9s\n",
      "  [QuantumEnt] Epoch 38/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 38 | loss=0.3522 | test_acc=0.8830 | time=20557.8s\n",
      "  [QuantumEnt] Epoch 39/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 39 | loss=0.3498 | test_acc=0.8810 | time=21096.0s\n",
      "  [QuantumEnt] Epoch 40/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 40 | loss=0.3475 | test_acc=0.8817 | time=21645.9s\n",
      "  [QuantumEnt] Epoch 41/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 41 | loss=0.3447 | test_acc=0.8807 | time=22182.2s\n",
      "  [QuantumEnt] Epoch 42/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 42 | loss=0.3433 | test_acc=0.8823 | time=22713.8s\n",
      "  [QuantumEnt] Epoch 43/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 43 | loss=0.3408 | test_acc=0.8823 | time=23230.2s\n",
      "  [QuantumEnt] Epoch 44/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 44 | loss=0.3393 | test_acc=0.8827 | time=23758.8s\n",
      "  [QuantumEnt] Epoch 45/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 45 | loss=0.3372 | test_acc=0.8823 | time=24273.7s\n",
      "  [QuantumEnt] Epoch 46/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 46 | loss=0.3356 | test_acc=0.8853 | time=24794.6s\n",
      "  [QuantumEnt] Epoch 47/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 47 | loss=0.3336 | test_acc=0.8840 | time=25310.1s\n",
      "  [QuantumEnt] Epoch 48/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 48 | loss=0.3318 | test_acc=0.8810 | time=25839.0s\n",
      "  [QuantumEnt] Epoch 49/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 49 | loss=0.3297 | test_acc=0.8847 | time=26368.2s\n",
      "  [QuantumEnt] Epoch 50/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 50 | loss=0.3283 | test_acc=0.8833 | time=26908.9s\n",
      "  [QuantumEnt] Epoch 51/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 51 | loss=0.3267 | test_acc=0.8847 | time=27457.7s\n",
      "  [QuantumEnt] Epoch 52/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 52 | loss=0.3253 | test_acc=0.8823 | time=27992.3s\n",
      "  [QuantumEnt] Epoch 53/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 53 | loss=0.3238 | test_acc=0.8847 | time=28543.4s\n",
      "  [QuantumEnt] Epoch 54/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 54 | loss=0.3212 | test_acc=0.8857 | time=29080.7s\n",
      "  [QuantumEnt] Epoch 55/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 55 | loss=0.3205 | test_acc=0.8853 | time=29621.5s\n",
      "  [QuantumEnt] Epoch 56/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 56 | loss=0.3188 | test_acc=0.8833 | time=30161.1s\n",
      "  [QuantumEnt] Epoch 57/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 57 | loss=0.3170 | test_acc=0.8850 | time=30703.1s\n",
      "  [QuantumEnt] Epoch 58/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 58 | loss=0.3154 | test_acc=0.8860 | time=31245.4s\n",
      "  [QuantumEnt] Epoch 59/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 59 | loss=0.3145 | test_acc=0.8880 | time=31802.6s\n",
      "  [QuantumEnt] Epoch 60/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 60 | loss=0.3129 | test_acc=0.8873 | time=32344.5s\n",
      "  [QuantumEnt] Epoch 61/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 61 | loss=0.3111 | test_acc=0.8880 | time=32893.6s\n",
      "  [QuantumEnt] Epoch 62/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 62 | loss=0.3103 | test_acc=0.8883 | time=33438.6s\n",
      "  [QuantumEnt] Epoch 63/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 63 | loss=0.3091 | test_acc=0.8883 | time=33968.7s\n",
      "  [QuantumEnt] Epoch 64/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 64 | loss=0.3075 | test_acc=0.8920 | time=34513.1s\n",
      "  [QuantumEnt] Epoch 65/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 65 | loss=0.3059 | test_acc=0.8910 | time=35061.9s\n",
      "  [QuantumEnt] Epoch 66/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 66 | loss=0.3042 | test_acc=0.8897 | time=35603.0s\n",
      "  [QuantumEnt] Epoch 67/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 67 | loss=0.3036 | test_acc=0.8890 | time=36143.6s\n",
      "  [QuantumEnt] Epoch 68/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 68 | loss=0.3017 | test_acc=0.8903 | time=36689.5s\n",
      "  [QuantumEnt] Epoch 69/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 69 | loss=0.3008 | test_acc=0.8910 | time=37231.6s\n",
      "  [QuantumEnt] Epoch 70/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 70 | loss=0.2997 | test_acc=0.8897 | time=37771.0s\n",
      "  [QuantumEnt] Epoch 71/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 71 | loss=0.2976 | test_acc=0.8907 | time=38312.0s\n",
      "  [QuantumEnt] Epoch 72/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 72 | loss=0.2971 | test_acc=0.8903 | time=38859.6s\n",
      "  [QuantumEnt] Epoch 73/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 73 | loss=0.2952 | test_acc=0.8877 | time=39399.4s\n",
      "  [QuantumEnt] Epoch 74/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 74 | loss=0.2938 | test_acc=0.8927 | time=39944.6s\n",
      "  [QuantumEnt] Epoch 75/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 75 | loss=0.2927 | test_acc=0.8907 | time=40481.9s\n",
      "  [QuantumEnt] Epoch 76/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 76 | loss=0.2917 | test_acc=0.8907 | time=41045.4s\n",
      "  [QuantumEnt] Epoch 77/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 77 | loss=0.2912 | test_acc=0.8887 | time=41591.2s\n",
      "  [QuantumEnt] Epoch 78/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 78 | loss=0.2893 | test_acc=0.8890 | time=42157.3s\n",
      "  [QuantumEnt] Epoch 79/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 79 | loss=0.2879 | test_acc=0.8897 | time=42694.8s\n",
      "  [QuantumEnt] Epoch 80/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 80 | loss=0.2874 | test_acc=0.8930 | time=43246.8s\n",
      "  [QuantumEnt] Epoch 81/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 81 | loss=0.2859 | test_acc=0.8927 | time=43782.8s\n",
      "  [QuantumEnt] Epoch 82/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 82 | loss=0.2849 | test_acc=0.8927 | time=44332.4s\n",
      "  [QuantumEnt] Epoch 83/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 83 | loss=0.2839 | test_acc=0.8917 | time=44866.9s\n",
      "  [QuantumEnt] Epoch 84/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 84 | loss=0.2827 | test_acc=0.8903 | time=45417.0s\n",
      "  [QuantumEnt] Epoch 85/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 85 | loss=0.2817 | test_acc=0.8937 | time=45958.6s\n",
      "  [QuantumEnt] Epoch 86/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 86 | loss=0.2811 | test_acc=0.8950 | time=46506.2s\n",
      "  [QuantumEnt] Epoch 87/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 87 | loss=0.2799 | test_acc=0.8927 | time=47056.4s\n",
      "  [QuantumEnt] Epoch 88/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 88 | loss=0.2796 | test_acc=0.8967 | time=47601.7s\n",
      "  [QuantumEnt] Epoch 89/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 89 | loss=0.2784 | test_acc=0.8930 | time=48137.5s\n",
      "  [QuantumEnt] Epoch 90/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 90 | loss=0.2776 | test_acc=0.8937 | time=48692.1s\n",
      "  [QuantumEnt] Epoch 91/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 91 | loss=0.2763 | test_acc=0.8927 | time=49234.2s\n",
      "  [QuantumEnt] Epoch 92/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 92 | loss=0.2762 | test_acc=0.8943 | time=49787.4s\n",
      "  [QuantumEnt] Epoch 93/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 93 | loss=0.2756 | test_acc=0.8953 | time=50322.4s\n",
      "  [QuantumEnt] Epoch 94/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 94 | loss=0.2750 | test_acc=0.8930 | time=50861.9s\n",
      "  [QuantumEnt] Epoch 95/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 95 | loss=0.2744 | test_acc=0.8947 | time=51395.1s\n",
      "  [QuantumEnt] Epoch 96/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 96 | loss=0.2736 | test_acc=0.8910 | time=51937.4s\n",
      "  [QuantumEnt] Epoch 97/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 97 | loss=0.2733 | test_acc=0.8933 | time=52473.2s\n",
      "  [QuantumEnt] Epoch 98/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 98 | loss=0.2729 | test_acc=0.8937 | time=53028.4s\n",
      "  [QuantumEnt] Epoch 99/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 99 | loss=0.2721 | test_acc=0.8957 | time=53571.8s\n",
      "  [QuantumEnt] Epoch 100/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 100 | loss=0.2711 | test_acc=0.8953 | time=54116.5s\n",
      "  [QuantumEnt] Epoch 101/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 101 | loss=0.2704 | test_acc=0.8950 | time=54666.0s\n",
      "  [QuantumEnt] Epoch 102/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 102 | loss=0.2694 | test_acc=0.8963 | time=55205.9s\n",
      "  [QuantumEnt] Epoch 103/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 103 | loss=0.2705 | test_acc=0.8953 | time=55732.4s\n",
      "  [QuantumEnt] Epoch 104/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 104 | loss=0.2690 | test_acc=0.8960 | time=56282.6s\n",
      "  [QuantumEnt] Epoch 105/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 105 | loss=0.2683 | test_acc=0.8917 | time=56835.2s\n",
      "  [QuantumEnt] Epoch 106/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 106 | loss=0.2681 | test_acc=0.8920 | time=57370.8s\n",
      "  [QuantumEnt] Epoch 107/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 107 | loss=0.2681 | test_acc=0.8940 | time=57909.7s\n",
      "  [QuantumEnt] Epoch 108/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 108 | loss=0.2676 | test_acc=0.8947 | time=58447.6s\n",
      "  [QuantumEnt] Early stop at epoch 108 (no improvement for 20 epochs)\n",
      "\n",
      "======================================================================\n",
      "SEED 123\n",
      "======================================================================\n",
      "\n",
      "  Training RealNet (seed=123)...\n",
      "  [Real] Epoch  1 | loss=1.2818 | test_acc=0.8693 | time=0.9s\n",
      "  [Real] Epoch  2 | loss=0.4208 | test_acc=0.9067 | time=1.9s\n",
      "  [Real] Epoch  3 | loss=0.2915 | test_acc=0.9173 | time=2.9s\n",
      "  [Real] Epoch  4 | loss=0.2444 | test_acc=0.9230 | time=3.8s\n",
      "  [Real] Epoch  5 | loss=0.2144 | test_acc=0.9263 | time=4.7s\n",
      "  [Real] Epoch  6 | loss=0.1903 | test_acc=0.9270 | time=5.7s\n",
      "  [Real] Epoch  7 | loss=0.1765 | test_acc=0.9277 | time=6.6s\n",
      "  [Real] Epoch  8 | loss=0.1657 | test_acc=0.9313 | time=7.6s\n",
      "  [Real] Epoch  9 | loss=0.1508 | test_acc=0.9320 | time=8.5s\n",
      "  [Real] Epoch 10 | loss=0.1375 | test_acc=0.9277 | time=9.5s\n",
      "  [Real] Epoch 11 | loss=0.1325 | test_acc=0.9330 | time=10.4s\n",
      "  [Real] Epoch 12 | loss=0.1203 | test_acc=0.9343 | time=11.3s\n",
      "  [Real] Epoch 13 | loss=0.1146 | test_acc=0.9323 | time=12.3s\n",
      "  [Real] Epoch 14 | loss=0.1087 | test_acc=0.9307 | time=13.3s\n",
      "  [Real] Epoch 15 | loss=0.1002 | test_acc=0.9320 | time=14.2s\n",
      "  [Real] Epoch 16 | loss=0.0949 | test_acc=0.9300 | time=15.2s\n",
      "  [Real] Epoch 17 | loss=0.0894 | test_acc=0.9290 | time=16.1s\n",
      "  [Real] Epoch 18 | loss=0.0856 | test_acc=0.9323 | time=17.1s\n",
      "  [Real] Epoch 19 | loss=0.0806 | test_acc=0.9293 | time=18.0s\n",
      "  [Real] Epoch 20 | loss=0.0751 | test_acc=0.9330 | time=19.0s\n",
      "  [Real] Early stop at epoch 20 (no improvement for 8 epochs)\n",
      "\n",
      "  → Preprocessor frozen with 12560 params\n",
      "\n",
      "  Training QuatNet with frozen preprocessor (seed=123)...\n",
      "  [Quat] Epoch  1 | loss=2.1721 | test_acc=0.6207 | time=1.1s\n",
      "  [Quat] Epoch  2 | loss=0.8290 | test_acc=0.8640 | time=2.2s\n",
      "  [Quat] Epoch  3 | loss=0.4583 | test_acc=0.9000 | time=3.3s\n",
      "  [Quat] Epoch  4 | loss=0.3230 | test_acc=0.9150 | time=4.3s\n",
      "  [Quat] Epoch  5 | loss=0.2562 | test_acc=0.9190 | time=5.4s\n",
      "  [Quat] Epoch  6 | loss=0.2161 | test_acc=0.9223 | time=6.5s\n",
      "  [Quat] Epoch  7 | loss=0.1895 | test_acc=0.9243 | time=7.6s\n",
      "  [Quat] Epoch  8 | loss=0.1703 | test_acc=0.9233 | time=8.7s\n",
      "  [Quat] Epoch  9 | loss=0.1558 | test_acc=0.9243 | time=9.8s\n",
      "  [Quat] Epoch 10 | loss=0.1443 | test_acc=0.9263 | time=10.9s\n",
      "  [Quat] Epoch 11 | loss=0.1350 | test_acc=0.9277 | time=12.0s\n",
      "  [Quat] Epoch 12 | loss=0.1272 | test_acc=0.9290 | time=13.0s\n",
      "  [Quat] Epoch 13 | loss=0.1206 | test_acc=0.9290 | time=14.1s\n",
      "  [Quat] Epoch 14 | loss=0.1150 | test_acc=0.9283 | time=15.2s\n",
      "  [Quat] Epoch 15 | loss=0.1100 | test_acc=0.9290 | time=16.3s\n",
      "  [Quat] Epoch 16 | loss=0.1060 | test_acc=0.9310 | time=17.4s\n",
      "  [Quat] Epoch 17 | loss=0.1021 | test_acc=0.9303 | time=18.5s\n",
      "  [Quat] Epoch 18 | loss=0.0987 | test_acc=0.9300 | time=19.6s\n",
      "  [Quat] Epoch 19 | loss=0.0956 | test_acc=0.9300 | time=20.7s\n",
      "  [Quat] Epoch 20 | loss=0.0930 | test_acc=0.9307 | time=21.8s\n",
      "  [Quat] Epoch 21 | loss=0.0905 | test_acc=0.9307 | time=22.9s\n",
      "  [Quat] Epoch 22 | loss=0.0881 | test_acc=0.9320 | time=24.0s\n",
      "  [Quat] Epoch 23 | loss=0.0861 | test_acc=0.9327 | time=25.1s\n",
      "  [Quat] Epoch 24 | loss=0.0841 | test_acc=0.9327 | time=26.2s\n",
      "  [Quat] Epoch 25 | loss=0.0824 | test_acc=0.9337 | time=27.2s\n",
      "  [Quat] Epoch 26 | loss=0.0807 | test_acc=0.9333 | time=28.3s\n",
      "  [Quat] Epoch 27 | loss=0.0793 | test_acc=0.9340 | time=29.4s\n",
      "  [Quat] Epoch 28 | loss=0.0780 | test_acc=0.9323 | time=30.5s\n",
      "  [Quat] Epoch 29 | loss=0.0765 | test_acc=0.9327 | time=31.6s\n",
      "  [Quat] Epoch 30 | loss=0.0752 | test_acc=0.9323 | time=32.7s\n",
      "  [Quat] Epoch 31 | loss=0.0741 | test_acc=0.9340 | time=33.8s\n",
      "  [Quat] Epoch 32 | loss=0.0730 | test_acc=0.9337 | time=34.9s\n",
      "  [Quat] Epoch 33 | loss=0.0720 | test_acc=0.9337 | time=36.0s\n",
      "  [Quat] Epoch 34 | loss=0.0711 | test_acc=0.9347 | time=37.1s\n",
      "  [Quat] Epoch 35 | loss=0.0701 | test_acc=0.9337 | time=38.2s\n",
      "  [Quat] Epoch 36 | loss=0.0692 | test_acc=0.9350 | time=39.3s\n",
      "  [Quat] Epoch 37 | loss=0.0683 | test_acc=0.9330 | time=40.5s\n",
      "  [Quat] Epoch 38 | loss=0.0677 | test_acc=0.9330 | time=41.5s\n",
      "  [Quat] Epoch 39 | loss=0.0668 | test_acc=0.9333 | time=42.6s\n",
      "  [Quat] Epoch 40 | loss=0.0662 | test_acc=0.9333 | time=43.7s\n",
      "\n",
      "  Training QuantumNet (NO entanglement, seed=123, lightning.gpu)...\n",
      "  [QuantumNoEnt] Epoch 1/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  1 | loss=1.6770 | test_acc=0.5837 | time=491.8s\n",
      "  [QuantumNoEnt] Epoch 2/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  2 | loss=1.1036 | test_acc=0.7077 | time=973.8s\n",
      "  [QuantumNoEnt] Epoch 3/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  3 | loss=0.8609 | test_acc=0.7613 | time=1452.0s\n",
      "  [QuantumNoEnt] Epoch 4/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  4 | loss=0.7149 | test_acc=0.7843 | time=1935.7s\n",
      "  [QuantumNoEnt] Epoch 5/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  5 | loss=0.6252 | test_acc=0.8107 | time=2419.7s\n",
      "  [QuantumNoEnt] Epoch 6/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  6 | loss=0.5632 | test_acc=0.8247 | time=2895.4s\n",
      "  [QuantumNoEnt] Epoch 7/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  7 | loss=0.5174 | test_acc=0.8390 | time=3391.0s\n",
      "  [QuantumNoEnt] Epoch 8/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  8 | loss=0.4821 | test_acc=0.8440 | time=3874.5s\n",
      "  [QuantumNoEnt] Epoch 9/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  9 | loss=0.4563 | test_acc=0.8463 | time=4354.9s\n",
      "  [QuantumNoEnt] Epoch 10/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 10 | loss=0.4381 | test_acc=0.8513 | time=4851.1s\n",
      "  [QuantumNoEnt] Epoch 11/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 11 | loss=0.4244 | test_acc=0.8523 | time=5339.6s\n",
      "  [QuantumNoEnt] Epoch 12/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 12 | loss=0.4129 | test_acc=0.8517 | time=5828.5s\n",
      "  [QuantumNoEnt] Epoch 13/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 13 | loss=0.4035 | test_acc=0.8533 | time=6316.6s\n",
      "  [QuantumNoEnt] Epoch 14/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 14 | loss=0.3963 | test_acc=0.8557 | time=6792.4s\n",
      "  [QuantumNoEnt] Epoch 15/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 15 | loss=0.3891 | test_acc=0.8557 | time=7270.7s\n",
      "  [QuantumNoEnt] Epoch 16/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 16 | loss=0.3831 | test_acc=0.8600 | time=7756.4s\n",
      "  [QuantumNoEnt] Epoch 17/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 17 | loss=0.3776 | test_acc=0.8607 | time=8233.9s\n",
      "  [QuantumNoEnt] Epoch 18/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 18 | loss=0.3721 | test_acc=0.8637 | time=8720.9s\n",
      "  [QuantumNoEnt] Epoch 19/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 19 | loss=0.3678 | test_acc=0.8627 | time=9216.3s\n",
      "  [QuantumNoEnt] Epoch 20/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 20 | loss=0.3629 | test_acc=0.8613 | time=9706.0s\n",
      "  [QuantumNoEnt] Epoch 21/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 21 | loss=0.3590 | test_acc=0.8660 | time=10201.7s\n",
      "  [QuantumNoEnt] Epoch 22/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 22 | loss=0.3545 | test_acc=0.8613 | time=10688.0s\n",
      "  [QuantumNoEnt] Epoch 23/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 23 | loss=0.3510 | test_acc=0.8633 | time=11178.5s\n",
      "  [QuantumNoEnt] Epoch 24/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 24 | loss=0.3479 | test_acc=0.8697 | time=11683.8s\n",
      "  [QuantumNoEnt] Epoch 25/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 25 | loss=0.3441 | test_acc=0.8667 | time=12178.6s\n",
      "  [QuantumNoEnt] Epoch 26/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 26 | loss=0.3409 | test_acc=0.8647 | time=12673.5s\n",
      "  [QuantumNoEnt] Epoch 27/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 27 | loss=0.3376 | test_acc=0.8720 | time=13183.1s\n",
      "  [QuantumNoEnt] Epoch 28/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 28 | loss=0.3349 | test_acc=0.8687 | time=13673.0s\n",
      "  [QuantumNoEnt] Epoch 29/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 29 | loss=0.3325 | test_acc=0.8670 | time=14172.3s\n",
      "  [QuantumNoEnt] Epoch 30/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 30 | loss=0.3302 | test_acc=0.8687 | time=14660.8s\n",
      "  [QuantumNoEnt] Epoch 31/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 31 | loss=0.3282 | test_acc=0.8703 | time=15130.9s\n",
      "  [QuantumNoEnt] Epoch 32/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 32 | loss=0.3269 | test_acc=0.8733 | time=15616.2s\n",
      "  [QuantumNoEnt] Epoch 33/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 33 | loss=0.3243 | test_acc=0.8770 | time=16118.0s\n",
      "  [QuantumNoEnt] Epoch 34/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 34 | loss=0.3238 | test_acc=0.8747 | time=16594.9s\n",
      "  [QuantumNoEnt] Epoch 35/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 35 | loss=0.3216 | test_acc=0.8747 | time=17089.4s\n",
      "  [QuantumNoEnt] Epoch 36/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 36 | loss=0.3205 | test_acc=0.8717 | time=17575.0s\n",
      "  [QuantumNoEnt] Epoch 37/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 37 | loss=0.3195 | test_acc=0.8733 | time=18055.0s\n",
      "  [QuantumNoEnt] Epoch 38/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 38 | loss=0.3174 | test_acc=0.8740 | time=18542.9s\n",
      "  [QuantumNoEnt] Epoch 39/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 39 | loss=0.3161 | test_acc=0.8767 | time=19031.3s\n",
      "  [QuantumNoEnt] Epoch 40/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 40 | loss=0.3157 | test_acc=0.8770 | time=19507.9s\n",
      "  [QuantumNoEnt] Epoch 41/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 41 | loss=0.3144 | test_acc=0.8740 | time=20000.0s\n",
      "  [QuantumNoEnt] Epoch 42/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 42 | loss=0.3130 | test_acc=0.8793 | time=20492.7s\n",
      "  [QuantumNoEnt] Epoch 43/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 43 | loss=0.3146 | test_acc=0.8793 | time=20978.8s\n",
      "  [QuantumNoEnt] Epoch 44/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 44 | loss=0.3125 | test_acc=0.8770 | time=21475.7s\n",
      "  [QuantumNoEnt] Epoch 45/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 45 | loss=0.3105 | test_acc=0.8790 | time=21958.6s\n",
      "  [QuantumNoEnt] Epoch 46/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 46 | loss=0.3117 | test_acc=0.8793 | time=22453.3s\n",
      "  [QuantumNoEnt] Epoch 47/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 47 | loss=0.3101 | test_acc=0.8773 | time=22935.9s\n",
      "  [QuantumNoEnt] Epoch 48/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 48 | loss=0.3091 | test_acc=0.8783 | time=23414.6s\n",
      "  [QuantumNoEnt] Epoch 49/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 49 | loss=0.3083 | test_acc=0.8797 | time=23900.6s\n",
      "  [QuantumNoEnt] Epoch 50/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 50 | loss=0.3092 | test_acc=0.8770 | time=24366.1s\n",
      "  [QuantumNoEnt] Epoch 51/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 51 | loss=0.3089 | test_acc=0.8747 | time=24851.9s\n",
      "  [QuantumNoEnt] Epoch 52/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 52 | loss=0.3071 | test_acc=0.8790 | time=25339.1s\n",
      "  [QuantumNoEnt] Epoch 53/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 53 | loss=0.3052 | test_acc=0.8770 | time=25817.3s\n",
      "  [QuantumNoEnt] Epoch 54/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 54 | loss=0.3064 | test_acc=0.8810 | time=26287.7s\n",
      "  [QuantumNoEnt] Epoch 55/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 55 | loss=0.3042 | test_acc=0.8780 | time=26775.7s\n",
      "  [QuantumNoEnt] Epoch 56/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 56 | loss=0.3047 | test_acc=0.8770 | time=27261.7s\n",
      "  [QuantumNoEnt] Epoch 57/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 57 | loss=0.3048 | test_acc=0.8800 | time=27752.3s\n",
      "  [QuantumNoEnt] Epoch 58/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 58 | loss=0.3041 | test_acc=0.8787 | time=28248.6s\n",
      "  [QuantumNoEnt] Epoch 59/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 59 | loss=0.3037 | test_acc=0.8793 | time=28737.3s\n",
      "  [QuantumNoEnt] Epoch 60/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 60 | loss=0.3037 | test_acc=0.8823 | time=29232.8s\n",
      "  [QuantumNoEnt] Epoch 61/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 61 | loss=0.3023 | test_acc=0.8810 | time=29714.7s\n",
      "  [QuantumNoEnt] Epoch 62/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 62 | loss=0.3021 | test_acc=0.8780 | time=30190.1s\n",
      "  [QuantumNoEnt] Epoch 63/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 63 | loss=0.3022 | test_acc=0.8793 | time=30663.2s\n",
      "  [QuantumNoEnt] Epoch 64/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 64 | loss=0.3018 | test_acc=0.8757 | time=31139.2s\n",
      "  [QuantumNoEnt] Epoch 65/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 65 | loss=0.3007 | test_acc=0.8787 | time=31612.5s\n",
      "  [QuantumNoEnt] Epoch 66/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 66 | loss=0.3008 | test_acc=0.8823 | time=32084.5s\n",
      "  [QuantumNoEnt] Epoch 67/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 67 | loss=0.3003 | test_acc=0.8813 | time=32568.4s\n",
      "  [QuantumNoEnt] Epoch 68/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 68 | loss=0.2997 | test_acc=0.8800 | time=33040.0s\n",
      "  [QuantumNoEnt] Epoch 69/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 69 | loss=0.2982 | test_acc=0.8817 | time=33527.6s\n",
      "  [QuantumNoEnt] Epoch 70/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 70 | loss=0.2985 | test_acc=0.8793 | time=34018.8s\n",
      "  [QuantumNoEnt] Epoch 71/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 71 | loss=0.2996 | test_acc=0.8780 | time=34505.8s\n",
      "  [QuantumNoEnt] Epoch 72/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 72 | loss=0.2976 | test_acc=0.8787 | time=34995.1s\n",
      "  [QuantumNoEnt] Epoch 73/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 73 | loss=0.2975 | test_acc=0.8793 | time=35496.8s\n",
      "  [QuantumNoEnt] Epoch 74/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 74 | loss=0.2987 | test_acc=0.8797 | time=35982.4s\n",
      "  [QuantumNoEnt] Epoch 75/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 75 | loss=0.2969 | test_acc=0.8817 | time=36458.9s\n",
      "  [QuantumNoEnt] Epoch 76/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 76 | loss=0.2969 | test_acc=0.8803 | time=36934.8s\n",
      "  [QuantumNoEnt] Epoch 77/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 77 | loss=0.2973 | test_acc=0.8773 | time=37398.6s\n",
      "  [QuantumNoEnt] Epoch 78/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 78 | loss=0.2972 | test_acc=0.8830 | time=37868.7s\n",
      "  [QuantumNoEnt] Epoch 79/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 79 | loss=0.2957 | test_acc=0.8787 | time=38333.5s\n",
      "  [QuantumNoEnt] Epoch 80/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 80 | loss=0.2940 | test_acc=0.8800 | time=38797.0s\n",
      "  [QuantumNoEnt] Epoch 81/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 81 | loss=0.2953 | test_acc=0.8800 | time=39270.5s\n",
      "  [QuantumNoEnt] Epoch 82/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 82 | loss=0.2962 | test_acc=0.8773 | time=39745.0s\n",
      "  [QuantumNoEnt] Epoch 83/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 83 | loss=0.2949 | test_acc=0.8803 | time=40210.9s\n",
      "  [QuantumNoEnt] Epoch 84/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 84 | loss=0.2943 | test_acc=0.8787 | time=40677.7s\n",
      "  [QuantumNoEnt] Epoch 85/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 85 | loss=0.2941 | test_acc=0.8803 | time=41155.2s\n",
      "  [QuantumNoEnt] Epoch 86/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 86 | loss=0.2935 | test_acc=0.8780 | time=41624.6s\n",
      "  [QuantumNoEnt] Epoch 87/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 87 | loss=0.2942 | test_acc=0.8833 | time=42090.1s\n",
      "  [QuantumNoEnt] Epoch 88/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 88 | loss=0.2944 | test_acc=0.8803 | time=42559.5s\n",
      "  [QuantumNoEnt] Epoch 89/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 89 | loss=0.2932 | test_acc=0.8800 | time=43025.8s\n",
      "  [QuantumNoEnt] Epoch 90/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 90 | loss=0.2945 | test_acc=0.8807 | time=43494.1s\n",
      "  [QuantumNoEnt] Epoch 91/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 91 | loss=0.2936 | test_acc=0.8800 | time=43959.3s\n",
      "  [QuantumNoEnt] Epoch 92/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 92 | loss=0.2929 | test_acc=0.8820 | time=44428.7s\n",
      "  [QuantumNoEnt] Epoch 93/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 93 | loss=0.2918 | test_acc=0.8820 | time=44895.4s\n",
      "  [QuantumNoEnt] Epoch 94/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 94 | loss=0.2933 | test_acc=0.8790 | time=45371.7s\n",
      "  [QuantumNoEnt] Epoch 95/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 95 | loss=0.2925 | test_acc=0.8780 | time=45858.4s\n",
      "  [QuantumNoEnt] Epoch 96/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 96 | loss=0.2926 | test_acc=0.8817 | time=46349.5s\n",
      "  [QuantumNoEnt] Epoch 97/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 97 | loss=0.2922 | test_acc=0.8840 | time=46843.3s\n",
      "  [QuantumNoEnt] Epoch 98/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 98 | loss=0.2917 | test_acc=0.8797 | time=47338.3s\n",
      "  [QuantumNoEnt] Epoch 99/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 99 | loss=0.2908 | test_acc=0.8803 | time=47826.0s\n",
      "  [QuantumNoEnt] Epoch 100/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 100 | loss=0.2908 | test_acc=0.8813 | time=48323.0s\n",
      "  [QuantumNoEnt] Epoch 101/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 101 | loss=0.2912 | test_acc=0.8790 | time=48822.8s\n",
      "  [QuantumNoEnt] Epoch 102/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 102 | loss=0.2900 | test_acc=0.8807 | time=49309.6s\n",
      "  [QuantumNoEnt] Epoch 103/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 103 | loss=0.2911 | test_acc=0.8797 | time=49801.8s\n",
      "  [QuantumNoEnt] Epoch 104/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 104 | loss=0.2898 | test_acc=0.8807 | time=50279.0s\n",
      "  [QuantumNoEnt] Epoch 105/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 105 | loss=0.2910 | test_acc=0.8810 | time=50750.8s\n",
      "  [QuantumNoEnt] Epoch 106/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 106 | loss=0.2900 | test_acc=0.8833 | time=51234.7s\n",
      "  [QuantumNoEnt] Epoch 107/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 107 | loss=0.2899 | test_acc=0.8787 | time=51718.9s\n",
      "  [QuantumNoEnt] Epoch 108/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 108 | loss=0.2898 | test_acc=0.8820 | time=52191.6s\n",
      "  [QuantumNoEnt] Epoch 109/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 109 | loss=0.2887 | test_acc=0.8807 | time=52674.4s\n",
      "  [QuantumNoEnt] Epoch 110/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 110 | loss=0.2889 | test_acc=0.8840 | time=53154.7s\n",
      "  [QuantumNoEnt] Epoch 111/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 111 | loss=0.2887 | test_acc=0.8790 | time=53640.8s\n",
      "  [QuantumNoEnt] Epoch 112/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 112 | loss=0.2892 | test_acc=0.8823 | time=54153.9s\n",
      "  [QuantumNoEnt] Epoch 113/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 113 | loss=0.2889 | test_acc=0.8817 | time=54656.5s\n",
      "  [QuantumNoEnt] Epoch 114/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 114 | loss=0.2881 | test_acc=0.8830 | time=55147.9s\n",
      "  [QuantumNoEnt] Epoch 115/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 115 | loss=0.2886 | test_acc=0.8773 | time=55646.9s\n",
      "  [QuantumNoEnt] Epoch 116/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 116 | loss=0.2874 | test_acc=0.8830 | time=56140.1s\n",
      "  [QuantumNoEnt] Epoch 117/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 117 | loss=0.2881 | test_acc=0.8820 | time=56632.6s\n",
      "  [QuantumNoEnt] Early stop at epoch 117 (no improvement for 20 epochs)\n",
      "\n",
      "  Training QuantumNet (WITH entanglement, seed=123, lightning.gpu)...\n",
      "  [QuantumEnt] Epoch 1/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  1 | loss=1.9643 | test_acc=0.5650 | time=546.4s\n",
      "  [QuantumEnt] Epoch 2/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  2 | loss=1.3838 | test_acc=0.5430 | time=1098.3s\n",
      "  [QuantumEnt] Epoch 3/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  3 | loss=1.1269 | test_acc=0.6010 | time=1654.0s\n",
      "  [QuantumEnt] Epoch 4/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  4 | loss=0.9858 | test_acc=0.7077 | time=2201.9s\n",
      "  [QuantumEnt] Epoch 5/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  5 | loss=0.8768 | test_acc=0.7690 | time=2736.0s\n",
      "  [QuantumEnt] Epoch 6/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  6 | loss=0.7908 | test_acc=0.7873 | time=3279.9s\n",
      "  [QuantumEnt] Epoch 7/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  7 | loss=0.7260 | test_acc=0.7993 | time=3827.1s\n",
      "  [QuantumEnt] Epoch 8/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  8 | loss=0.6777 | test_acc=0.8027 | time=4375.3s\n",
      "  [QuantumEnt] Epoch 9/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  9 | loss=0.6374 | test_acc=0.8130 | time=4916.7s\n",
      "  [QuantumEnt] Epoch 10/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 10 | loss=0.6029 | test_acc=0.8167 | time=5484.7s\n",
      "  [QuantumEnt] Epoch 11/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 11 | loss=0.5733 | test_acc=0.8220 | time=6025.0s\n",
      "  [QuantumEnt] Epoch 12/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 12 | loss=0.5452 | test_acc=0.8323 | time=6574.4s\n",
      "  [QuantumEnt] Epoch 13/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 13 | loss=0.5173 | test_acc=0.8410 | time=7107.6s\n",
      "  [QuantumEnt] Epoch 14/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 14 | loss=0.4935 | test_acc=0.8427 | time=7651.5s\n",
      "  [QuantumEnt] Epoch 15/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 15 | loss=0.4755 | test_acc=0.8457 | time=8182.5s\n",
      "  [QuantumEnt] Epoch 16/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 16 | loss=0.4599 | test_acc=0.8483 | time=8724.6s\n",
      "  [QuantumEnt] Epoch 17/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 17 | loss=0.4463 | test_acc=0.8507 | time=9258.9s\n",
      "  [QuantumEnt] Epoch 18/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 18 | loss=0.4344 | test_acc=0.8547 | time=9815.7s\n",
      "  [QuantumEnt] Epoch 19/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 19 | loss=0.4238 | test_acc=0.8590 | time=10368.0s\n",
      "  [QuantumEnt] Epoch 20/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 20 | loss=0.4128 | test_acc=0.8647 | time=10925.8s\n",
      "  [QuantumEnt] Epoch 21/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 21 | loss=0.4027 | test_acc=0.8617 | time=11490.3s\n",
      "  [QuantumEnt] Epoch 22/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 22 | loss=0.3932 | test_acc=0.8667 | time=12064.9s\n",
      "  [QuantumEnt] Epoch 23/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 23 | loss=0.3849 | test_acc=0.8703 | time=12633.6s\n",
      "  [QuantumEnt] Epoch 24/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 24 | loss=0.3773 | test_acc=0.8713 | time=13190.3s\n",
      "  [QuantumEnt] Epoch 25/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 25 | loss=0.3689 | test_acc=0.8740 | time=13759.4s\n",
      "  [QuantumEnt] Epoch 26/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 26 | loss=0.3615 | test_acc=0.8757 | time=14309.9s\n",
      "  [QuantumEnt] Epoch 27/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 27 | loss=0.3550 | test_acc=0.8697 | time=14862.8s\n",
      "  [QuantumEnt] Epoch 28/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 28 | loss=0.3495 | test_acc=0.8743 | time=15423.9s\n",
      "  [QuantumEnt] Epoch 29/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 29 | loss=0.3439 | test_acc=0.8740 | time=15980.5s\n",
      "  [QuantumEnt] Epoch 30/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 30 | loss=0.3394 | test_acc=0.8750 | time=16528.7s\n",
      "  [QuantumEnt] Epoch 31/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 31 | loss=0.3345 | test_acc=0.8773 | time=17093.0s\n",
      "  [QuantumEnt] Epoch 32/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 32 | loss=0.3293 | test_acc=0.8757 | time=17640.3s\n",
      "  [QuantumEnt] Epoch 33/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 33 | loss=0.3261 | test_acc=0.8777 | time=18198.9s\n",
      "  [QuantumEnt] Epoch 34/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 34 | loss=0.3230 | test_acc=0.8760 | time=18764.3s\n",
      "  [QuantumEnt] Epoch 35/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 35 | loss=0.3192 | test_acc=0.8777 | time=19319.2s\n",
      "  [QuantumEnt] Epoch 36/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 36 | loss=0.3164 | test_acc=0.8743 | time=19885.0s\n",
      "  [QuantumEnt] Epoch 37/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 37 | loss=0.3142 | test_acc=0.8793 | time=20441.1s\n",
      "  [QuantumEnt] Epoch 38/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 38 | loss=0.3112 | test_acc=0.8780 | time=21004.7s\n",
      "  [QuantumEnt] Epoch 39/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 39 | loss=0.3092 | test_acc=0.8793 | time=21583.5s\n",
      "  [QuantumEnt] Epoch 40/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 40 | loss=0.3069 | test_acc=0.8800 | time=22140.1s\n",
      "  [QuantumEnt] Epoch 41/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 41 | loss=0.3045 | test_acc=0.8790 | time=22689.7s\n",
      "  [QuantumEnt] Epoch 42/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 42 | loss=0.3040 | test_acc=0.8797 | time=23242.8s\n",
      "  [QuantumEnt] Epoch 43/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 43 | loss=0.3011 | test_acc=0.8787 | time=23794.8s\n",
      "  [QuantumEnt] Epoch 44/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 44 | loss=0.3003 | test_acc=0.8820 | time=24339.0s\n",
      "  [QuantumEnt] Epoch 45/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 45 | loss=0.2987 | test_acc=0.8803 | time=24900.0s\n",
      "  [QuantumEnt] Epoch 46/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 46 | loss=0.2971 | test_acc=0.8813 | time=25443.1s\n",
      "  [QuantumEnt] Epoch 47/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 47 | loss=0.2960 | test_acc=0.8810 | time=25998.9s\n",
      "  [QuantumEnt] Epoch 48/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 48 | loss=0.2954 | test_acc=0.8787 | time=26543.5s\n",
      "  [QuantumEnt] Epoch 49/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 49 | loss=0.2944 | test_acc=0.8790 | time=27110.3s\n",
      "  [QuantumEnt] Epoch 50/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 50 | loss=0.2934 | test_acc=0.8803 | time=27651.9s\n",
      "  [QuantumEnt] Epoch 51/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 51 | loss=0.2918 | test_acc=0.8797 | time=28190.5s\n",
      "  [QuantumEnt] Epoch 52/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 52 | loss=0.2909 | test_acc=0.8787 | time=28739.5s\n",
      "  [QuantumEnt] Epoch 53/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 53 | loss=0.2903 | test_acc=0.8810 | time=29286.8s\n",
      "  [QuantumEnt] Epoch 54/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 54 | loss=0.2899 | test_acc=0.8790 | time=29832.7s\n",
      "  [QuantumEnt] Epoch 55/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 55 | loss=0.2883 | test_acc=0.8840 | time=30384.9s\n",
      "  [QuantumEnt] Epoch 56/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 56 | loss=0.2880 | test_acc=0.8800 | time=30934.2s\n",
      "  [QuantumEnt] Epoch 57/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 57 | loss=0.2871 | test_acc=0.8840 | time=31500.1s\n",
      "  [QuantumEnt] Epoch 58/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 58 | loss=0.2859 | test_acc=0.8800 | time=32056.1s\n",
      "  [QuantumEnt] Epoch 59/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 59 | loss=0.2860 | test_acc=0.8793 | time=32612.2s\n",
      "  [QuantumEnt] Epoch 60/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 60 | loss=0.2843 | test_acc=0.8833 | time=33163.3s\n",
      "  [QuantumEnt] Epoch 61/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 61 | loss=0.2856 | test_acc=0.8820 | time=33708.7s\n",
      "  [QuantumEnt] Epoch 62/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 62 | loss=0.2837 | test_acc=0.8820 | time=34270.0s\n",
      "  [QuantumEnt] Epoch 63/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 63 | loss=0.2843 | test_acc=0.8827 | time=34816.3s\n",
      "  [QuantumEnt] Epoch 64/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 64 | loss=0.2830 | test_acc=0.8840 | time=35377.8s\n",
      "  [QuantumEnt] Epoch 65/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 65 | loss=0.2823 | test_acc=0.8803 | time=35918.2s\n",
      "  [QuantumEnt] Epoch 66/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 66 | loss=0.2828 | test_acc=0.8840 | time=36461.4s\n",
      "  [QuantumEnt] Epoch 67/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 67 | loss=0.2807 | test_acc=0.8857 | time=36990.8s\n",
      "  [QuantumEnt] Epoch 68/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 68 | loss=0.2813 | test_acc=0.8817 | time=37520.4s\n",
      "  [QuantumEnt] Epoch 69/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 69 | loss=0.2802 | test_acc=0.8797 | time=38042.5s\n",
      "  [QuantumEnt] Epoch 70/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 70 | loss=0.2801 | test_acc=0.8813 | time=38569.2s\n",
      "  [QuantumEnt] Epoch 71/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 71 | loss=0.2800 | test_acc=0.8847 | time=39113.9s\n",
      "  [QuantumEnt] Epoch 72/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 72 | loss=0.2794 | test_acc=0.8837 | time=39671.0s\n",
      "  [QuantumEnt] Epoch 73/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 73 | loss=0.2788 | test_acc=0.8847 | time=40218.3s\n",
      "  [QuantumEnt] Epoch 74/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 74 | loss=0.2787 | test_acc=0.8860 | time=40759.9s\n",
      "  [QuantumEnt] Epoch 75/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 75 | loss=0.2779 | test_acc=0.8840 | time=41298.2s\n",
      "  [QuantumEnt] Epoch 76/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 76 | loss=0.2780 | test_acc=0.8840 | time=41833.5s\n",
      "  [QuantumEnt] Epoch 77/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 77 | loss=0.2775 | test_acc=0.8840 | time=42376.0s\n",
      "  [QuantumEnt] Epoch 78/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 78 | loss=0.2775 | test_acc=0.8833 | time=42917.9s\n",
      "  [QuantumEnt] Epoch 79/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 79 | loss=0.2769 | test_acc=0.8847 | time=43465.4s\n",
      "  [QuantumEnt] Epoch 80/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 80 | loss=0.2767 | test_acc=0.8847 | time=44002.2s\n",
      "  [QuantumEnt] Epoch 81/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 81 | loss=0.2761 | test_acc=0.8833 | time=44545.0s\n",
      "  [QuantumEnt] Epoch 82/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 82 | loss=0.2760 | test_acc=0.8850 | time=45099.9s\n",
      "  [QuantumEnt] Epoch 83/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 83 | loss=0.2757 | test_acc=0.8843 | time=45652.8s\n",
      "  [QuantumEnt] Epoch 84/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 84 | loss=0.2754 | test_acc=0.8847 | time=46198.1s\n",
      "  [QuantumEnt] Epoch 85/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 85 | loss=0.2745 | test_acc=0.8833 | time=46746.6s\n",
      "  [QuantumEnt] Epoch 86/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 86 | loss=0.2744 | test_acc=0.8833 | time=47280.7s\n",
      "  [QuantumEnt] Epoch 87/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 87 | loss=0.2742 | test_acc=0.8877 | time=47812.0s\n",
      "  [QuantumEnt] Epoch 88/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 88 | loss=0.2735 | test_acc=0.8870 | time=48345.3s\n",
      "  [QuantumEnt] Epoch 89/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 89 | loss=0.2732 | test_acc=0.8850 | time=48879.9s\n",
      "  [QuantumEnt] Epoch 90/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 90 | loss=0.2740 | test_acc=0.8873 | time=49415.5s\n",
      "  [QuantumEnt] Epoch 91/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 91 | loss=0.2736 | test_acc=0.8857 | time=49942.7s\n",
      "  [QuantumEnt] Epoch 92/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 92 | loss=0.2739 | test_acc=0.8863 | time=50488.4s\n",
      "  [QuantumEnt] Epoch 93/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 93 | loss=0.2729 | test_acc=0.8870 | time=51014.6s\n",
      "  [QuantumEnt] Epoch 94/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 94 | loss=0.2717 | test_acc=0.8817 | time=51543.0s\n",
      "  [QuantumEnt] Epoch 95/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 95 | loss=0.2718 | test_acc=0.8857 | time=52063.9s\n",
      "  [QuantumEnt] Epoch 96/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 96 | loss=0.2728 | test_acc=0.8890 | time=52595.3s\n",
      "  [QuantumEnt] Epoch 97/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 97 | loss=0.2715 | test_acc=0.8860 | time=53130.7s\n",
      "  [QuantumEnt] Epoch 98/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 98 | loss=0.2710 | test_acc=0.8827 | time=53663.4s\n",
      "  [QuantumEnt] Epoch 99/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 99 | loss=0.2714 | test_acc=0.8857 | time=54197.6s\n",
      "  [QuantumEnt] Epoch 100/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 100 | loss=0.2712 | test_acc=0.8850 | time=54730.0s\n",
      "  [QuantumEnt] Epoch 101/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 101 | loss=0.2710 | test_acc=0.8873 | time=55271.9s\n",
      "  [QuantumEnt] Epoch 102/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 102 | loss=0.2705 | test_acc=0.8857 | time=55821.1s\n",
      "  [QuantumEnt] Epoch 103/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 103 | loss=0.2700 | test_acc=0.8907 | time=56364.7s\n",
      "  [QuantumEnt] Epoch 104/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 104 | loss=0.2704 | test_acc=0.8883 | time=56913.9s\n",
      "  [QuantumEnt] Epoch 105/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 105 | loss=0.2701 | test_acc=0.8867 | time=57461.1s\n",
      "  [QuantumEnt] Epoch 106/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 106 | loss=0.2701 | test_acc=0.8873 | time=58016.1s\n",
      "  [QuantumEnt] Epoch 107/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 107 | loss=0.2698 | test_acc=0.8847 | time=58538.8s\n",
      "  [QuantumEnt] Epoch 108/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 108 | loss=0.2685 | test_acc=0.8873 | time=59075.2s\n",
      "  [QuantumEnt] Epoch 109/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 109 | loss=0.2701 | test_acc=0.8870 | time=59605.5s\n",
      "  [QuantumEnt] Epoch 110/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 110 | loss=0.2696 | test_acc=0.8877 | time=60138.7s\n",
      "  [QuantumEnt] Epoch 111/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 111 | loss=0.2687 | test_acc=0.8887 | time=60668.3s\n",
      "  [QuantumEnt] Epoch 112/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 112 | loss=0.2685 | test_acc=0.8860 | time=61201.7s\n",
      "  [QuantumEnt] Epoch 113/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 113 | loss=0.2687 | test_acc=0.8883 | time=61730.7s\n",
      "  [QuantumEnt] Epoch 114/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 114 | loss=0.2687 | test_acc=0.8877 | time=62267.9s\n",
      "  [QuantumEnt] Epoch 115/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 115 | loss=0.2680 | test_acc=0.8887 | time=62795.5s\n",
      "  [QuantumEnt] Epoch 116/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 116 | loss=0.2685 | test_acc=0.8887 | time=63325.6s\n",
      "  [QuantumEnt] Epoch 117/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 117 | loss=0.2679 | test_acc=0.8883 | time=63852.0s\n",
      "  [QuantumEnt] Epoch 118/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 118 | loss=0.2675 | test_acc=0.8890 | time=64377.3s\n",
      "  [QuantumEnt] Epoch 119/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 119 | loss=0.2677 | test_acc=0.8870 | time=64910.1s\n",
      "  [QuantumEnt] Epoch 120/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 120 | loss=0.2671 | test_acc=0.8897 | time=65453.0s\n",
      "  [QuantumEnt] Epoch 121/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 121 | loss=0.2678 | test_acc=0.8880 | time=65996.3s\n",
      "  [QuantumEnt] Epoch 122/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 122 | loss=0.2674 | test_acc=0.8877 | time=66533.5s\n",
      "  [QuantumEnt] Epoch 123/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 123 | loss=0.2668 | test_acc=0.8883 | time=67074.0s\n",
      "  [QuantumEnt] Early stop at epoch 123 (no improvement for 20 epochs)\n",
      "\n",
      "======================================================================\n",
      "SEED 456\n",
      "======================================================================\n",
      "\n",
      "  Training RealNet (seed=456)...\n",
      "  [Real] Epoch  1 | loss=1.2768 | test_acc=0.8823 | time=1.1s\n",
      "  [Real] Epoch  2 | loss=0.4085 | test_acc=0.9053 | time=2.2s\n",
      "  [Real] Epoch  3 | loss=0.2994 | test_acc=0.9157 | time=3.1s\n",
      "  [Real] Epoch  4 | loss=0.2562 | test_acc=0.9200 | time=4.2s\n",
      "  [Real] Epoch  5 | loss=0.2297 | test_acc=0.9227 | time=5.2s\n",
      "  [Real] Epoch  6 | loss=0.2043 | test_acc=0.9240 | time=6.2s\n",
      "  [Real] Epoch  7 | loss=0.1854 | test_acc=0.9240 | time=7.2s\n",
      "  [Real] Epoch  8 | loss=0.1701 | test_acc=0.9317 | time=8.1s\n",
      "  [Real] Epoch  9 | loss=0.1553 | test_acc=0.9253 | time=9.1s\n",
      "  [Real] Epoch 10 | loss=0.1493 | test_acc=0.9290 | time=10.2s\n",
      "  [Real] Epoch 11 | loss=0.1363 | test_acc=0.9327 | time=11.2s\n",
      "  [Real] Epoch 12 | loss=0.1272 | test_acc=0.9310 | time=12.2s\n",
      "  [Real] Epoch 13 | loss=0.1176 | test_acc=0.9310 | time=13.2s\n",
      "  [Real] Epoch 14 | loss=0.1153 | test_acc=0.9353 | time=14.2s\n",
      "  [Real] Epoch 15 | loss=0.1060 | test_acc=0.9317 | time=15.2s\n",
      "  [Real] Epoch 16 | loss=0.0992 | test_acc=0.9320 | time=16.5s\n",
      "  [Real] Epoch 17 | loss=0.0922 | test_acc=0.9327 | time=17.8s\n",
      "  [Real] Epoch 18 | loss=0.0882 | test_acc=0.9347 | time=19.0s\n",
      "  [Real] Epoch 19 | loss=0.0866 | test_acc=0.9370 | time=20.2s\n",
      "  [Real] Epoch 20 | loss=0.0797 | test_acc=0.9297 | time=21.5s\n",
      "  [Real] Epoch 21 | loss=0.0769 | test_acc=0.9307 | time=22.7s\n",
      "  [Real] Epoch 22 | loss=0.0859 | test_acc=0.9333 | time=23.9s\n",
      "  [Real] Epoch 23 | loss=0.0703 | test_acc=0.9337 | time=25.0s\n",
      "  [Real] Epoch 24 | loss=0.0643 | test_acc=0.9360 | time=26.0s\n",
      "  [Real] Epoch 25 | loss=0.0621 | test_acc=0.9340 | time=26.9s\n",
      "  [Real] Epoch 26 | loss=0.0576 | test_acc=0.9280 | time=27.9s\n",
      "  [Real] Epoch 27 | loss=0.0576 | test_acc=0.9267 | time=28.9s\n",
      "  [Real] Early stop at epoch 27 (no improvement for 8 epochs)\n",
      "\n",
      "  → Preprocessor frozen with 12560 params\n",
      "\n",
      "  Training QuatNet with frozen preprocessor (seed=456)...\n",
      "  [Quat] Epoch  1 | loss=1.9512 | test_acc=0.6323 | time=1.1s\n",
      "  [Quat] Epoch  2 | loss=0.8122 | test_acc=0.8583 | time=2.2s\n",
      "  [Quat] Epoch  3 | loss=0.4721 | test_acc=0.9003 | time=3.4s\n",
      "  [Quat] Epoch  4 | loss=0.3383 | test_acc=0.9143 | time=4.6s\n",
      "  [Quat] Epoch  5 | loss=0.2690 | test_acc=0.9227 | time=5.9s\n",
      "  [Quat] Epoch  6 | loss=0.2268 | test_acc=0.9253 | time=7.1s\n",
      "  [Quat] Epoch  7 | loss=0.1979 | test_acc=0.9293 | time=8.4s\n",
      "  [Quat] Epoch  8 | loss=0.1770 | test_acc=0.9293 | time=9.7s\n",
      "  [Quat] Epoch  9 | loss=0.1609 | test_acc=0.9310 | time=11.0s\n",
      "  [Quat] Epoch 10 | loss=0.1482 | test_acc=0.9300 | time=12.2s\n",
      "  [Quat] Epoch 11 | loss=0.1377 | test_acc=0.9323 | time=13.3s\n",
      "  [Quat] Epoch 12 | loss=0.1289 | test_acc=0.9327 | time=14.5s\n",
      "  [Quat] Epoch 13 | loss=0.1214 | test_acc=0.9330 | time=15.8s\n",
      "  [Quat] Epoch 14 | loss=0.1150 | test_acc=0.9327 | time=16.9s\n",
      "  [Quat] Epoch 15 | loss=0.1094 | test_acc=0.9327 | time=18.1s\n",
      "  [Quat] Epoch 16 | loss=0.1046 | test_acc=0.9330 | time=19.2s\n",
      "  [Quat] Epoch 17 | loss=0.1002 | test_acc=0.9330 | time=20.4s\n",
      "  [Quat] Epoch 18 | loss=0.0963 | test_acc=0.9320 | time=21.6s\n",
      "  [Quat] Epoch 19 | loss=0.0930 | test_acc=0.9323 | time=22.8s\n",
      "  [Quat] Epoch 20 | loss=0.0900 | test_acc=0.9307 | time=24.0s\n",
      "  [Quat] Epoch 21 | loss=0.0872 | test_acc=0.9317 | time=25.2s\n",
      "  [Quat] Early stop at epoch 21 (no improvement for 8 epochs)\n",
      "\n",
      "  Training QuantumNet (NO entanglement, seed=456, lightning.gpu)...\n",
      "  [QuantumNoEnt] Epoch 1/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  1 | loss=1.7229 | test_acc=0.7420 | time=478.9s\n",
      "  [QuantumNoEnt] Epoch 2/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  2 | loss=1.0328 | test_acc=0.7907 | time=965.4s\n",
      "  [QuantumNoEnt] Epoch 3/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  3 | loss=0.7567 | test_acc=0.8117 | time=1459.6s\n",
      "  [QuantumNoEnt] Epoch 4/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  4 | loss=0.6376 | test_acc=0.8267 | time=1955.7s\n",
      "  [QuantumNoEnt] Epoch 5/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  5 | loss=0.5685 | test_acc=0.8290 | time=2442.9s\n",
      "  [QuantumNoEnt] Epoch 6/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  6 | loss=0.5221 | test_acc=0.8317 | time=2916.0s\n",
      "  [QuantumNoEnt] Epoch 7/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  7 | loss=0.4895 | test_acc=0.8307 | time=3391.1s\n",
      "  [QuantumNoEnt] Epoch 8/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  8 | loss=0.4659 | test_acc=0.8333 | time=3866.5s\n",
      "  [QuantumNoEnt] Epoch 9/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch  9 | loss=0.4499 | test_acc=0.8233 | time=4347.6s\n",
      "  [QuantumNoEnt] Epoch 10/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 10 | loss=0.4379 | test_acc=0.8220 | time=4832.1s\n",
      "  [QuantumNoEnt] Epoch 11/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 11 | loss=0.4279 | test_acc=0.8193 | time=5320.6s\n",
      "  [QuantumNoEnt] Epoch 12/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 12 | loss=0.4200 | test_acc=0.8280 | time=5801.3s\n",
      "  [QuantumNoEnt] Epoch 13/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 13 | loss=0.4133 | test_acc=0.8353 | time=6284.7s\n",
      "  [QuantumNoEnt] Epoch 14/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 14 | loss=0.4071 | test_acc=0.8263 | time=6778.5s\n",
      "  [QuantumNoEnt] Epoch 15/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 15 | loss=0.4019 | test_acc=0.8460 | time=7250.5s\n",
      "  [QuantumNoEnt] Epoch 16/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 16 | loss=0.3959 | test_acc=0.8420 | time=7731.1s\n",
      "  [QuantumNoEnt] Epoch 17/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 17 | loss=0.3910 | test_acc=0.8520 | time=8206.2s\n",
      "  [QuantumNoEnt] Epoch 18/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 18 | loss=0.3854 | test_acc=0.8560 | time=8680.4s\n",
      "  [QuantumNoEnt] Epoch 19/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 19 | loss=0.3785 | test_acc=0.8583 | time=9169.7s\n",
      "  [QuantumNoEnt] Epoch 20/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 20 | loss=0.3719 | test_acc=0.8643 | time=9644.1s\n",
      "  [QuantumNoEnt] Epoch 21/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 21 | loss=0.3645 | test_acc=0.8680 | time=10118.3s\n",
      "  [QuantumNoEnt] Epoch 22/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 22 | loss=0.3562 | test_acc=0.8727 | time=10599.3s\n",
      "  [QuantumNoEnt] Epoch 23/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 23 | loss=0.3479 | test_acc=0.8713 | time=11092.8s\n",
      "  [QuantumNoEnt] Epoch 24/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 24 | loss=0.3410 | test_acc=0.8720 | time=11575.4s\n",
      "  [QuantumNoEnt] Epoch 25/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 25 | loss=0.3324 | test_acc=0.8727 | time=12068.8s\n",
      "  [QuantumNoEnt] Epoch 26/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 26 | loss=0.3259 | test_acc=0.8713 | time=12570.3s\n",
      "  [QuantumNoEnt] Epoch 27/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 27 | loss=0.3181 | test_acc=0.8717 | time=13073.2s\n",
      "  [QuantumNoEnt] Epoch 28/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 28 | loss=0.3129 | test_acc=0.8770 | time=13588.2s\n",
      "  [QuantumNoEnt] Epoch 29/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 29 | loss=0.3073 | test_acc=0.8760 | time=14093.4s\n",
      "  [QuantumNoEnt] Epoch 30/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 30 | loss=0.3022 | test_acc=0.8767 | time=14614.9s\n",
      "  [QuantumNoEnt] Epoch 31/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 31 | loss=0.2966 | test_acc=0.8817 | time=15130.0s\n",
      "  [QuantumNoEnt] Epoch 32/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 32 | loss=0.2916 | test_acc=0.8790 | time=15674.7s\n",
      "  [QuantumNoEnt] Epoch 33/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 33 | loss=0.2880 | test_acc=0.8840 | time=16202.5s\n",
      "  [QuantumNoEnt] Epoch 34/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 34 | loss=0.2839 | test_acc=0.8797 | time=16742.8s\n",
      "  [QuantumNoEnt] Epoch 35/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 35 | loss=0.2805 | test_acc=0.8790 | time=17276.0s\n",
      "  [QuantumNoEnt] Epoch 36/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 36 | loss=0.2767 | test_acc=0.8800 | time=17817.5s\n",
      "  [QuantumNoEnt] Epoch 37/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 37 | loss=0.2737 | test_acc=0.8800 | time=18296.8s\n",
      "  [QuantumNoEnt] Epoch 38/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 38 | loss=0.2702 | test_acc=0.8760 | time=18772.3s\n",
      "  [QuantumNoEnt] Epoch 39/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 39 | loss=0.2692 | test_acc=0.8810 | time=19270.2s\n",
      "  [QuantumNoEnt] Epoch 40/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 40 | loss=0.2676 | test_acc=0.8800 | time=19768.3s\n",
      "  [QuantumNoEnt] Epoch 41/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 41 | loss=0.2654 | test_acc=0.8827 | time=20262.8s\n",
      "  [QuantumNoEnt] Epoch 42/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 42 | loss=0.2635 | test_acc=0.8823 | time=20761.1s\n",
      "  [QuantumNoEnt] Epoch 43/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 43 | loss=0.2631 | test_acc=0.8840 | time=21258.9s\n",
      "  [QuantumNoEnt] Epoch 44/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 44 | loss=0.2609 | test_acc=0.8820 | time=21744.6s\n",
      "  [QuantumNoEnt] Epoch 45/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 45 | loss=0.2608 | test_acc=0.8823 | time=22246.8s\n",
      "  [QuantumNoEnt] Epoch 46/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 46 | loss=0.2595 | test_acc=0.8820 | time=22732.3s\n",
      "  [QuantumNoEnt] Epoch 47/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 47 | loss=0.2580 | test_acc=0.8843 | time=23228.4s\n",
      "  [QuantumNoEnt] Epoch 48/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 48 | loss=0.2569 | test_acc=0.8810 | time=23706.3s\n",
      "  [QuantumNoEnt] Epoch 49/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 49 | loss=0.2557 | test_acc=0.8827 | time=24185.8s\n",
      "  [QuantumNoEnt] Epoch 50/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 50 | loss=0.2557 | test_acc=0.8837 | time=24671.6s\n",
      "  [QuantumNoEnt] Epoch 51/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 51 | loss=0.2545 | test_acc=0.8817 | time=25148.2s\n",
      "  [QuantumNoEnt] Epoch 52/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 52 | loss=0.2536 | test_acc=0.8860 | time=25624.6s\n",
      "  [QuantumNoEnt] Epoch 53/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 53 | loss=0.2522 | test_acc=0.8843 | time=26113.6s\n",
      "  [QuantumNoEnt] Epoch 54/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 54 | loss=0.2527 | test_acc=0.8877 | time=26591.6s\n",
      "  [QuantumNoEnt] Epoch 55/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 55 | loss=0.2519 | test_acc=0.8830 | time=27071.8s\n",
      "  [QuantumNoEnt] Epoch 56/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 56 | loss=0.2519 | test_acc=0.8853 | time=27556.7s\n",
      "  [QuantumNoEnt] Epoch 57/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 57 | loss=0.2503 | test_acc=0.8867 | time=28035.1s\n",
      "  [QuantumNoEnt] Epoch 58/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 58 | loss=0.2515 | test_acc=0.8827 | time=28511.5s\n",
      "  [QuantumNoEnt] Epoch 59/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 59 | loss=0.2499 | test_acc=0.8857 | time=28983.7s\n",
      "  [QuantumNoEnt] Epoch 60/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 60 | loss=0.2479 | test_acc=0.8867 | time=29466.9s\n",
      "  [QuantumNoEnt] Epoch 61/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 61 | loss=0.2494 | test_acc=0.8860 | time=29949.6s\n",
      "  [QuantumNoEnt] Epoch 62/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 62 | loss=0.2492 | test_acc=0.8850 | time=30446.2s\n",
      "  [QuantumNoEnt] Epoch 63/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 63 | loss=0.2482 | test_acc=0.8823 | time=30930.2s\n",
      "  [QuantumNoEnt] Epoch 64/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 64 | loss=0.2473 | test_acc=0.8863 | time=31410.9s\n",
      "  [QuantumNoEnt] Epoch 65/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 65 | loss=0.2475 | test_acc=0.8873 | time=31899.1s\n",
      "  [QuantumNoEnt] Epoch 66/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 66 | loss=0.2470 | test_acc=0.8887 | time=32379.0s\n",
      "  [QuantumNoEnt] Epoch 67/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 67 | loss=0.2465 | test_acc=0.8837 | time=32856.9s\n",
      "  [QuantumNoEnt] Epoch 68/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 68 | loss=0.2451 | test_acc=0.8837 | time=33334.7s\n",
      "  [QuantumNoEnt] Epoch 69/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 69 | loss=0.2455 | test_acc=0.8890 | time=33814.2s\n",
      "  [QuantumNoEnt] Epoch 70/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 70 | loss=0.2450 | test_acc=0.8853 | time=34296.0s\n",
      "  [QuantumNoEnt] Epoch 71/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 71 | loss=0.2445 | test_acc=0.8890 | time=34800.9s\n",
      "  [QuantumNoEnt] Epoch 72/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 72 | loss=0.2439 | test_acc=0.8860 | time=35278.0s\n",
      "  [QuantumNoEnt] Epoch 73/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 73 | loss=0.2440 | test_acc=0.8873 | time=35754.7s\n",
      "  [QuantumNoEnt] Epoch 74/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 74 | loss=0.2439 | test_acc=0.8877 | time=36245.7s\n",
      "  [QuantumNoEnt] Epoch 75/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 75 | loss=0.2441 | test_acc=0.8880 | time=36730.6s\n",
      "  [QuantumNoEnt] Epoch 76/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 76 | loss=0.2434 | test_acc=0.8870 | time=37209.5s\n",
      "  [QuantumNoEnt] Epoch 77/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 77 | loss=0.2428 | test_acc=0.8830 | time=37696.6s\n",
      "  [QuantumNoEnt] Epoch 78/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 78 | loss=0.2414 | test_acc=0.8890 | time=38181.1s\n",
      "  [QuantumNoEnt] Epoch 79/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 79 | loss=0.2423 | test_acc=0.8857 | time=38654.8s\n",
      "  [QuantumNoEnt] Epoch 80/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 80 | loss=0.2406 | test_acc=0.8873 | time=39143.3s\n",
      "  [QuantumNoEnt] Epoch 81/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 81 | loss=0.2410 | test_acc=0.8883 | time=39631.9s\n",
      "  [QuantumNoEnt] Epoch 82/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 82 | loss=0.2413 | test_acc=0.8850 | time=40110.2s\n",
      "  [QuantumNoEnt] Epoch 83/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 83 | loss=0.2404 | test_acc=0.8847 | time=40599.3s\n",
      "  [QuantumNoEnt] Epoch 84/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 84 | loss=0.2400 | test_acc=0.8887 | time=41074.8s\n",
      "  [QuantumNoEnt] Epoch 85/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 85 | loss=0.2405 | test_acc=0.8853 | time=41565.0s\n",
      "  [QuantumNoEnt] Epoch 86/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 86 | loss=0.2399 | test_acc=0.8877 | time=42048.8s\n",
      "  [QuantumNoEnt] Epoch 87/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 87 | loss=0.2388 | test_acc=0.8843 | time=42524.7s\n",
      "  [QuantumNoEnt] Epoch 88/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 88 | loss=0.2391 | test_acc=0.8853 | time=43009.5s\n",
      "  [QuantumNoEnt] Epoch 89/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumNoEnt] Epoch 89 | loss=0.2382 | test_acc=0.8870 | time=43490.9s\n",
      "  [QuantumNoEnt] Early stop at epoch 89 (no improvement for 20 epochs)\n",
      "\n",
      "  Training QuantumNet (WITH entanglement, seed=456, lightning.gpu)...\n",
      "  [QuantumEnt] Epoch 1/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  1 | loss=2.0368 | test_acc=0.4503 | time=526.8s\n",
      "  [QuantumEnt] Epoch 2/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  2 | loss=1.5373 | test_acc=0.5600 | time=1076.8s\n",
      "  [QuantumEnt] Epoch 3/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  3 | loss=1.2679 | test_acc=0.6370 | time=1611.0s\n",
      "  [QuantumEnt] Epoch 4/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  4 | loss=1.1161 | test_acc=0.6943 | time=2163.6s\n",
      "  [QuantumEnt] Epoch 5/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  5 | loss=1.0142 | test_acc=0.7360 | time=2694.4s\n",
      "  [QuantumEnt] Epoch 6/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  6 | loss=0.9368 | test_acc=0.7650 | time=3238.4s\n",
      "  [QuantumEnt] Epoch 7/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  7 | loss=0.8703 | test_acc=0.7807 | time=3773.4s\n",
      "  [QuantumEnt] Epoch 8/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  8 | loss=0.8108 | test_acc=0.7923 | time=4332.0s\n",
      "  [QuantumEnt] Epoch 9/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch  9 | loss=0.7575 | test_acc=0.7973 | time=4870.7s\n",
      "  [QuantumEnt] Epoch 10/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 10 | loss=0.7149 | test_acc=0.8060 | time=5417.3s\n",
      "  [QuantumEnt] Epoch 11/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 11 | loss=0.6805 | test_acc=0.8067 | time=5948.8s\n",
      "  [QuantumEnt] Epoch 12/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 12 | loss=0.6540 | test_acc=0.8100 | time=6487.6s\n",
      "  [QuantumEnt] Epoch 13/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 13 | loss=0.6321 | test_acc=0.8110 | time=7024.3s\n",
      "  [QuantumEnt] Epoch 14/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 14 | loss=0.6132 | test_acc=0.8130 | time=7569.8s\n",
      "  [QuantumEnt] Epoch 15/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 15 | loss=0.5976 | test_acc=0.8140 | time=8111.4s\n",
      "  [QuantumEnt] Epoch 16/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 16 | loss=0.5823 | test_acc=0.8160 | time=8649.9s\n",
      "  [QuantumEnt] Epoch 17/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 17 | loss=0.5693 | test_acc=0.8220 | time=9188.4s\n",
      "  [QuantumEnt] Epoch 18/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 18 | loss=0.5545 | test_acc=0.8250 | time=9730.6s\n",
      "  [QuantumEnt] Epoch 19/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 19 | loss=0.5385 | test_acc=0.8317 | time=10284.3s\n",
      "  [QuantumEnt] Epoch 20/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 20 | loss=0.5197 | test_acc=0.8393 | time=10846.1s\n",
      "  [QuantumEnt] Epoch 21/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 21 | loss=0.5001 | test_acc=0.8463 | time=11387.9s\n",
      "  [QuantumEnt] Epoch 22/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 22 | loss=0.4822 | test_acc=0.8513 | time=11940.9s\n",
      "  [QuantumEnt] Epoch 23/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 23 | loss=0.4664 | test_acc=0.8530 | time=12484.9s\n",
      "  [QuantumEnt] Epoch 24/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 24 | loss=0.4518 | test_acc=0.8580 | time=13030.8s\n",
      "  [QuantumEnt] Epoch 25/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 25 | loss=0.4398 | test_acc=0.8597 | time=13577.9s\n",
      "  [QuantumEnt] Epoch 26/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 26 | loss=0.4288 | test_acc=0.8600 | time=14117.9s\n",
      "  [QuantumEnt] Epoch 27/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 27 | loss=0.4189 | test_acc=0.8610 | time=14657.1s\n",
      "  [QuantumEnt] Epoch 28/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 28 | loss=0.4085 | test_acc=0.8627 | time=15194.1s\n",
      "  [QuantumEnt] Epoch 29/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 29 | loss=0.4003 | test_acc=0.8603 | time=15748.5s\n",
      "  [QuantumEnt] Epoch 30/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 30 | loss=0.3933 | test_acc=0.8600 | time=16297.6s\n",
      "  [QuantumEnt] Epoch 31/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 31 | loss=0.3863 | test_acc=0.8677 | time=16871.3s\n",
      "  [QuantumEnt] Epoch 32/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 32 | loss=0.3806 | test_acc=0.8633 | time=17420.5s\n",
      "  [QuantumEnt] Epoch 33/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 33 | loss=0.3743 | test_acc=0.8647 | time=17989.9s\n",
      "  [QuantumEnt] Epoch 34/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 34 | loss=0.3694 | test_acc=0.8737 | time=18529.8s\n",
      "  [QuantumEnt] Epoch 35/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 35 | loss=0.3643 | test_acc=0.8727 | time=19085.4s\n",
      "  [QuantumEnt] Epoch 36/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 36 | loss=0.3602 | test_acc=0.8703 | time=19633.3s\n",
      "  [QuantumEnt] Epoch 37/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 37 | loss=0.3558 | test_acc=0.8687 | time=20180.5s\n",
      "  [QuantumEnt] Epoch 38/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 38 | loss=0.3520 | test_acc=0.8713 | time=20731.2s\n",
      "  [QuantumEnt] Epoch 39/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 39 | loss=0.3481 | test_acc=0.8713 | time=21329.4s\n",
      "  [QuantumEnt] Epoch 40/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 40 | loss=0.3449 | test_acc=0.8713 | time=21911.7s\n",
      "  [QuantumEnt] Epoch 41/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 41 | loss=0.3416 | test_acc=0.8733 | time=22455.5s\n",
      "  [QuantumEnt] Epoch 42/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 42 | loss=0.3390 | test_acc=0.8717 | time=23037.6s\n",
      "  [QuantumEnt] Epoch 43/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 43 | loss=0.3358 | test_acc=0.8760 | time=23590.6s\n",
      "  [QuantumEnt] Epoch 44/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 44 | loss=0.3338 | test_acc=0.8750 | time=24137.1s\n",
      "  [QuantumEnt] Epoch 45/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 45 | loss=0.3308 | test_acc=0.8747 | time=24694.0s\n",
      "  [QuantumEnt] Epoch 46/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 46 | loss=0.3279 | test_acc=0.8777 | time=25244.0s\n",
      "  [QuantumEnt] Epoch 47/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 47 | loss=0.3258 | test_acc=0.8780 | time=25789.5s\n",
      "  [QuantumEnt] Epoch 48/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 48 | loss=0.3236 | test_acc=0.8790 | time=26324.1s\n",
      "  [QuantumEnt] Epoch 49/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 49 | loss=0.3212 | test_acc=0.8757 | time=26866.7s\n",
      "  [QuantumEnt] Epoch 50/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 50 | loss=0.3186 | test_acc=0.8797 | time=27397.7s\n",
      "  [QuantumEnt] Epoch 51/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 51 | loss=0.3176 | test_acc=0.8790 | time=27943.4s\n",
      "  [QuantumEnt] Epoch 52/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 52 | loss=0.3150 | test_acc=0.8797 | time=28479.2s\n",
      "  [QuantumEnt] Epoch 53/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 53 | loss=0.3141 | test_acc=0.8783 | time=29025.7s\n",
      "  [QuantumEnt] Epoch 54/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 54 | loss=0.3118 | test_acc=0.8780 | time=29576.1s\n",
      "  [QuantumEnt] Epoch 55/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 55 | loss=0.3108 | test_acc=0.8813 | time=30121.2s\n",
      "  [QuantumEnt] Epoch 56/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 56 | loss=0.3089 | test_acc=0.8820 | time=30663.8s\n",
      "  [QuantumEnt] Epoch 57/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 57 | loss=0.3080 | test_acc=0.8840 | time=31204.0s\n",
      "  [QuantumEnt] Epoch 58/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 58 | loss=0.3056 | test_acc=0.8787 | time=31741.8s\n",
      "  [QuantumEnt] Epoch 59/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 59 | loss=0.3047 | test_acc=0.8817 | time=32289.4s\n",
      "  [QuantumEnt] Epoch 60/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 60 | loss=0.3042 | test_acc=0.8800 | time=32827.6s\n",
      "  [QuantumEnt] Epoch 61/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 61 | loss=0.3017 | test_acc=0.8807 | time=33384.6s\n",
      "  [QuantumEnt] Epoch 62/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 62 | loss=0.3013 | test_acc=0.8813 | time=33945.7s\n",
      "  [QuantumEnt] Epoch 63/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 63 | loss=0.3003 | test_acc=0.8830 | time=34505.3s\n",
      "  [QuantumEnt] Epoch 64/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 64 | loss=0.2989 | test_acc=0.8777 | time=35055.5s\n",
      "  [QuantumEnt] Epoch 65/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 65 | loss=0.2980 | test_acc=0.8807 | time=35624.2s\n",
      "  [QuantumEnt] Epoch 66/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 66 | loss=0.2973 | test_acc=0.8810 | time=36178.0s\n",
      "  [QuantumEnt] Epoch 67/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 67 | loss=0.2954 | test_acc=0.8800 | time=36726.5s\n",
      "  [QuantumEnt] Epoch 68/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 68 | loss=0.2941 | test_acc=0.8823 | time=37266.7s\n",
      "  [QuantumEnt] Epoch 69/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 69 | loss=0.2937 | test_acc=0.8830 | time=37811.4s\n",
      "  [QuantumEnt] Epoch 70/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 70 | loss=0.2931 | test_acc=0.8813 | time=38357.5s\n",
      "  [QuantumEnt] Epoch 71/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 71 | loss=0.2913 | test_acc=0.8850 | time=38904.7s\n",
      "  [QuantumEnt] Epoch 72/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 72 | loss=0.2905 | test_acc=0.8797 | time=39446.0s\n",
      "  [QuantumEnt] Epoch 73/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 73 | loss=0.2896 | test_acc=0.8823 | time=39993.0s\n",
      "  [QuantumEnt] Epoch 74/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 74 | loss=0.2897 | test_acc=0.8817 | time=40534.8s\n",
      "  [QuantumEnt] Epoch 75/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 75 | loss=0.2882 | test_acc=0.8827 | time=41080.1s\n",
      "  [QuantumEnt] Epoch 76/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 76 | loss=0.2868 | test_acc=0.8820 | time=41630.4s\n",
      "  [QuantumEnt] Epoch 77/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 77 | loss=0.2872 | test_acc=0.8833 | time=42185.4s\n",
      "  [QuantumEnt] Epoch 78/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 78 | loss=0.2852 | test_acc=0.8820 | time=42741.0s\n",
      "  [QuantumEnt] Epoch 79/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 79 | loss=0.2849 | test_acc=0.8827 | time=43293.5s\n",
      "  [QuantumEnt] Epoch 80/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 80 | loss=0.2849 | test_acc=0.8877 | time=43853.1s\n",
      "  [QuantumEnt] Epoch 81/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 81 | loss=0.2833 | test_acc=0.8847 | time=44404.9s\n",
      "  [QuantumEnt] Epoch 82/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 82 | loss=0.2831 | test_acc=0.8860 | time=44969.8s\n",
      "  [QuantumEnt] Epoch 83/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 83 | loss=0.2817 | test_acc=0.8827 | time=45523.9s\n",
      "  [QuantumEnt] Epoch 84/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 84 | loss=0.2811 | test_acc=0.8847 | time=46082.7s\n",
      "  [QuantumEnt] Epoch 85/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 85 | loss=0.2811 | test_acc=0.8840 | time=46631.5s\n",
      "  [QuantumEnt] Epoch 86/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 86 | loss=0.2805 | test_acc=0.8843 | time=47181.0s\n",
      "  [QuantumEnt] Epoch 87/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 87 | loss=0.2803 | test_acc=0.8853 | time=47709.2s\n",
      "  [QuantumEnt] Epoch 88/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 88 | loss=0.2793 | test_acc=0.8853 | time=48253.6s\n",
      "  [QuantumEnt] Epoch 89/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 89 | loss=0.2784 | test_acc=0.8857 | time=48804.9s\n",
      "  [QuantumEnt] Epoch 90/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 90 | loss=0.2775 | test_acc=0.8837 | time=49359.6s\n",
      "  [QuantumEnt] Epoch 91/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 91 | loss=0.2775 | test_acc=0.8867 | time=49913.1s\n",
      "  [QuantumEnt] Epoch 92/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 92 | loss=0.2760 | test_acc=0.8857 | time=50474.1s\n",
      "  [QuantumEnt] Epoch 93/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 93 | loss=0.2766 | test_acc=0.8840 | time=51034.2s\n",
      "  [QuantumEnt] Epoch 94/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 94 | loss=0.2748 | test_acc=0.8873 | time=51583.4s\n",
      "  [QuantumEnt] Epoch 95/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 95 | loss=0.2753 | test_acc=0.8870 | time=52121.5s\n",
      "  [QuantumEnt] Epoch 96/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 96 | loss=0.2740 | test_acc=0.8863 | time=52656.2s\n",
      "  [QuantumEnt] Epoch 97/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 97 | loss=0.2744 | test_acc=0.8857 | time=53192.1s\n",
      "  [QuantumEnt] Epoch 98/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 98 | loss=0.2731 | test_acc=0.8850 | time=53727.8s\n",
      "  [QuantumEnt] Epoch 99/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 99 | loss=0.2734 | test_acc=0.8857 | time=54265.4s\n",
      "  [QuantumEnt] Epoch 100/200\n",
      "    Batch 450/469, samples: 14432\n",
      "  [QuantumEnt] Epoch 100 | loss=0.2716 | test_acc=0.8857 | time=54801.4s\n",
      "  [QuantumEnt] Early stop at epoch 100 (no improvement for 20 epochs)\n",
      "\n",
      "======================================================================\n",
      "AGGREGATED RESULTS (mean ± std over seeds)\n",
      "======================================================================\n",
      "\n",
      "Real    :\n",
      "  Accuracy:   0.9359 ± 0.0011\n",
      "  Time:       24.6s (avg)\n",
      "  Epochs:     24.3 (avg)\n",
      "  Parameters: 14,298\n",
      "\n",
      "Quat    :\n",
      "  Accuracy:   0.9337 ± 0.0009\n",
      "  Time:       38.4s (avg)\n",
      "  Epochs:     33.7 (avg)\n",
      "  Parameters: 1,000 trainable (head), 13,560 total\n",
      "\n",
      "QNoEnt  :\n",
      "  Accuracy:   0.8824 ± 0.0061\n",
      "  Time:       39974.6s (avg)\n",
      "  Epochs:     82.3 (avg)\n",
      "  Parameters: 162 trainable (head), 12,722 total\n",
      "\n",
      "QEnt    :\n",
      "  Accuracy:   0.8917 ± 0.0037\n",
      "  Time:       60107.6s (avg)\n",
      "  Epochs:     110.3 (avg)\n",
      "  Parameters: 162 trainable (head), 12,722 total\n",
      "\n",
      "======================================================================\n",
      "COMPARATIVE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "1. Quat vs Real:\n",
      "   Gap: 0.22 percentage points\n",
      "   Quat captures 99.8% of Real performance\n",
      "\n",
      "2. Quantum (no ent) vs Real:\n",
      "   Gap: 5.34 percentage points\n",
      "   QNoEnt captures 94.3% of Real performance\n",
      "\n",
      "3. Quantum (ent) vs Real:\n",
      "   Gap: 4.42 percentage points\n",
      "   QEnt captures 95.3% of Real performance\n",
      "\n",
      "4. Quantum (ent) vs Quantum (no ent):\n",
      "   Gap: -0.92 percentage points\n",
      "   → Entanglement improves performance.\n",
      "\n",
      "5. Quantum vs Quaternion:\n",
      "   Gap (Quat - QNoEnt): 5.12 points\n",
      "   Gap (Quat - QEnt):   4.20 points\n",
      "\n",
      "======================================================================\n",
      "KEY INTERPRETATION HINTS\n",
      "======================================================================\n",
      "Check:\n",
      "  • How close Quat is to Real (does classical SU(2) keep up with MLP?).\n",
      "  • Whether QNoEnt ≈ Quat (quantum SU(2) w/o entanglement vs quaternion).\n",
      "  • Whether QEnt > QNoEnt (empirical value of entanglement on MNIST).\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Clean SU(2) Comparison: Real vs Quaternion vs Quantum (LIGHTNING)\n",
    "===================================================================\n",
    "\n",
    "Research Question:\n",
    "Are quaternion networks (classical SU(2)) approximations that capture\n",
    "most of what quantum circuits do, without needing entanglement?\n",
    "\n",
    "Lightning Acceleration:\n",
    "- Uses pennylane-lightning-gpu if available (~50-100x speedup)\n",
    "- Falls back to lightning.qubit (CPU) if no GPU (~10x speedup)\n",
    "- Same architecture as SANER version (16-D bottleneck)\n",
    "\n",
    "Install: pip install pennylane pennylane-lightning pennylane-lightning-gpu\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Try to import PennyLane and set quantum device\n",
    "try:\n",
    "    import pennylane as qml\n",
    "    QUANTUM_DEVICE = \"lightning.gpu\"\n",
    "    PENNYLANE_AVAILABLE = True\n",
    "    print(\"✓ Using lightning.gpu device (requires: pip install pennylane-lightning-gpu)\")\n",
    "except ImportError:\n",
    "    PENNYLANE_AVAILABLE = False\n",
    "    QUANTUM_DEVICE = None\n",
    "    print(\"✗ PennyLane not installed - quantum models disabled\")\n",
    "    print(\"  Install with: pip install pennylane pennylane-lightning-gpu\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using PyTorch device: {device}\")\n",
    "\n",
    "# ============================================\n",
    "# Quaternion utilities (PyTorch tensors)\n",
    "# ============================================\n",
    "\n",
    "def q_normalize(q):\n",
    "    norm = torch.linalg.norm(q, dim=-1, keepdim=True) + 1e-8\n",
    "    return q / norm\n",
    "\n",
    "def q_conj(q):\n",
    "    w, x, y, z = torch.unbind(q, dim=-1)\n",
    "    return torch.stack([w, -x, -y, -z], dim=-1)\n",
    "\n",
    "def q_mul(a, b):\n",
    "    \"\"\"Hamilton product of two quaternions\"\"\"\n",
    "    aw, ax, ay, az = torch.unbind(a, dim=-1)\n",
    "    bw, bx, by, bz = torch.unbind(b, dim=-1)\n",
    "\n",
    "    w = aw * bw - ax * bx - ay * by - az * bz\n",
    "    x = aw * bx + ax * bw + ay * bz - az * by\n",
    "    y = aw * by - ax * bz + ay * bw + az * bx\n",
    "    z = aw * bz + ax * by - ay * bx + az * bw\n",
    "\n",
    "    return torch.stack([w, x, y, z], dim=-1)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Shared Bottleneck Preprocessor: 784 → 16\n",
    "# ============================================\n",
    "\n",
    "class SharedPreprocessor(nn.Module):\n",
    "    \"\"\"Shared classical feature extractor: 784 → 16\"\"\"\n",
    "    def __init__(self, input_dim=784, bottleneck_dim=16):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, bottleneck_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.tanh(self.fc(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Real-valued Head and Network\n",
    "# ============================================\n",
    "\n",
    "class RealHead(nn.Module):\n",
    "    \"\"\"Standard MLP: 16 → 64 → 10\"\"\"\n",
    "    def __init__(self, bottleneck_dim=16, hidden_dim=64, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(bottleneck_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RealNet(nn.Module):\n",
    "    \"\"\"Complete Real network: Preprocessor + RealHead\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.preprocessor = SharedPreprocessor(784, 16)\n",
    "        self.head = RealHead(16, 64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.preprocessor(x)\n",
    "        return self.head(features)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Quaternion Head and Network\n",
    "# ============================================\n",
    "\n",
    "class QuaternionLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \"\"\"\n",
    "        in_features, out_features are in \"quaternion units\".\n",
    "        Internally weight: (out_features, in_features, 4)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features, 4))\n",
    "        self.bias = nn.Parameter(torch.empty(out_features, 4))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.weight, mean=0.0, std=0.1)\n",
    "        with torch.no_grad():\n",
    "            self.weight[:] = q_normalize(self.weight)\n",
    "            nn.init.constant_(self.bias[..., 0], 1.0)\n",
    "            nn.init.constant_(self.bias[..., 1:], 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, in_features, 4)\n",
    "        Returns: (B, out_features, 4)\n",
    "        \"\"\"\n",
    "        w = self.weight.unsqueeze(0)\n",
    "        x_exp = x.unsqueeze(1)\n",
    "        prod = q_mul(w, x_exp)\n",
    "        out = prod.sum(dim=2) + self.bias\n",
    "        return out\n",
    "\n",
    "\n",
    "class QuatHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Quaternion head: 4 quats → 16 quats → 10 quats → 10 logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.quat_fc1 = QuaternionLinear(4, 16)\n",
    "        self.quat_fc2 = QuaternionLinear(16, num_classes)\n",
    "\n",
    "    def real_to_quat(self, x):\n",
    "        \"\"\"Convert 16 real features to 4 quaternions\"\"\"\n",
    "        B = x.size(0)\n",
    "        return x.view(B, 4, 4)\n",
    "\n",
    "    def quat_to_real(self, q):\n",
    "        \"\"\"Extract real part of quaternions for classification\"\"\"\n",
    "        return q[..., 0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        q_in = self.real_to_quat(x)\n",
    "        hq = self.quat_fc1(q_in)\n",
    "        hq = q_normalize(hq)\n",
    "        hq = torch.tanh(hq)\n",
    "        q_out = self.quat_fc2(hq)\n",
    "        logits = self.quat_to_real(q_out)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class QuatNet(nn.Module):\n",
    "    \"\"\"Complete Quaternion network: Preprocessor + QuatHead\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.preprocessor = SharedPreprocessor(784, 16)\n",
    "        self.head = QuatHead(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.preprocessor(x)\n",
    "        return self.head(features)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Quantum Head (Lightning-accelerated)\n",
    "# ============================================\n",
    "\n",
    "if PENNYLANE_AVAILABLE:\n",
    "    class QuantumHead(nn.Module):\n",
    "        \"\"\"\n",
    "        VQC with 4 qubits, 3 layers → 10 classes.\n",
    "        Uses Lightning acceleration (GPU or CPU).\n",
    "        \"\"\"\n",
    "        def __init__(self, n_qubits=4, n_layers=3, num_classes=10, \n",
    "                     use_entanglement=True, device_name=None):\n",
    "            super().__init__()\n",
    "            self.n_qubits = n_qubits\n",
    "            self.n_layers = n_layers\n",
    "            self.use_entanglement = use_entanglement\n",
    "\n",
    "            # Map 16 features → n_qubits\n",
    "            self.feature_select = nn.Linear(16, n_qubits)\n",
    "\n",
    "            # Use specified device or default\n",
    "            if device_name is None:\n",
    "                device_name = QUANTUM_DEVICE\n",
    "            \n",
    "            # Quantum device\n",
    "            self.dev = qml.device(device_name, wires=n_qubits)\n",
    "\n",
    "            # Use adjoint differentiation for lightning (much faster)\n",
    "            diff_method = \"adjoint\" if \"lightning\" in device_name else \"parameter-shift\"\n",
    "\n",
    "            @qml.qnode(self.dev, interface=\"torch\", diff_method=diff_method)\n",
    "            def quantum_circuit(inputs, weights):\n",
    "                \"\"\"\n",
    "                Single-sample circuit.\n",
    "                inputs: (n_qubits,)\n",
    "                weights: (n_layers, n_qubits, 2)\n",
    "                \"\"\"\n",
    "                for layer in range(n_layers):\n",
    "                    # Data re-uploading\n",
    "                    for i in range(n_qubits):\n",
    "                        qml.RY(inputs[i], wires=i)\n",
    "\n",
    "                    # Trainable rotations\n",
    "                    for i in range(n_qubits):\n",
    "                        qml.RY(weights[layer, i, 0], wires=i)\n",
    "                        qml.RZ(weights[layer, i, 1], wires=i)\n",
    "\n",
    "                    # Optional entanglement\n",
    "                    if self.use_entanglement:\n",
    "                        for i in range(n_qubits - 1):\n",
    "                            qml.CNOT(wires=[i, i + 1])\n",
    "                        if n_qubits > 2:\n",
    "                            qml.CNOT(wires=[n_qubits - 1, 0])\n",
    "\n",
    "                return [\n",
    "                    qml.expval(qml.PauliZ(0)),\n",
    "                    qml.expval(qml.PauliZ(1)),\n",
    "                    qml.expval(qml.PauliZ(2)),\n",
    "                    qml.expval(qml.PauliZ(3)),\n",
    "                    qml.expval(qml.PauliZ(0) @ qml.PauliZ(1)),\n",
    "                    qml.expval(qml.PauliZ(2) @ qml.PauliZ(3))\n",
    "                ]\n",
    "\n",
    "            self.quantum_circuit = quantum_circuit\n",
    "\n",
    "            weight_shape = (n_layers, n_qubits, 2)\n",
    "            self.q_weights = nn.Parameter(torch.randn(weight_shape) * 0.1)\n",
    "            self.fc_out = nn.Linear(6, num_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            \"\"\"\n",
    "            Process samples with progress tracking.\n",
    "            x: (batch, 16) real bottleneck features\n",
    "            \"\"\"\n",
    "            batch_size = x.size(0)\n",
    "            x = torch.tanh(self.feature_select(x))\n",
    "\n",
    "            # Process in chunks for memory management\n",
    "            chunk_size = 32\n",
    "            quantum_outputs = []\n",
    "\n",
    "            for start_idx in range(0, batch_size, chunk_size):\n",
    "                end_idx = min(start_idx + chunk_size, batch_size)\n",
    "                chunk = x[start_idx:end_idx]\n",
    "\n",
    "                chunk_outputs = []\n",
    "                for i in range(chunk.size(0)):\n",
    "                    q_raw = self.quantum_circuit(chunk[i], self.q_weights)\n",
    "                    if isinstance(q_raw, (list, tuple)):\n",
    "                        q_out = torch.stack(q_raw)\n",
    "                    else:\n",
    "                        q_out = q_raw\n",
    "                    chunk_outputs.append(q_out)\n",
    "\n",
    "                quantum_outputs.extend(chunk_outputs)\n",
    "\n",
    "            # Convert to tensor (cast to float32)\n",
    "            quantum_outputs = torch.stack(quantum_outputs).float()\n",
    "            quantum_outputs = quantum_outputs.to(self.fc_out.weight.dtype)\n",
    "\n",
    "            output = self.fc_out(quantum_outputs)\n",
    "            return output\n",
    "\n",
    "\n",
    "    class QuantumNet(nn.Module):\n",
    "        \"\"\"Complete Quantum network: Preprocessor + QuantumHead\"\"\"\n",
    "        def __init__(self, use_entanglement=True):\n",
    "            super().__init__()\n",
    "            self.preprocessor = SharedPreprocessor(784, 16)\n",
    "            self.head = QuantumHead(\n",
    "                n_qubits=4, n_layers=3, num_classes=10,\n",
    "                use_entanglement=use_entanglement\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            features = self.preprocessor(x)\n",
    "            return self.head(features)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Training and Evaluation\n",
    "# ============================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, show_progress=True):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_samples += x.size(0)\n",
    "\n",
    "        if show_progress and batch_idx % 50 == 0:\n",
    "            print(f\"    Batch {batch_idx}/{len(loader)}, samples: {total_samples}\", end=\"\\r\")\n",
    "\n",
    "    if show_progress:\n",
    "        print()\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "def train_with_early_stopping(model, train_loader, test_loader, optimizer,\n",
    "                              device, max_epochs=40, patience=8, name=\"Model\"):\n",
    "    if isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    start = time.time()\n",
    "    last_acc = 0.0\n",
    "\n",
    "    # Show progress for quantum models, suppress for fast models\n",
    "    show_progress = \"Quantum\" in name\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        if show_progress:\n",
    "            print(f\"  [{name}] Epoch {epoch}/{max_epochs}\")\n",
    "        \n",
    "        loss = train_one_epoch(model, train_loader, optimizer, device, show_progress)\n",
    "        acc = evaluate(model, test_loader, device)\n",
    "        last_acc = acc\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"  [{name}] Epoch {epoch:2d} | loss={loss:.4f} \"\n",
    "              f\"| test_acc={acc:.4f} | time={elapsed:.1f}s\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"  [{name}] Early stop at epoch {epoch} \"\n",
    "                  f\"(no improvement for {patience} epochs)\")\n",
    "            break\n",
    "\n",
    "    total_time = time.time() - start\n",
    "    return {\n",
    "        \"best_acc\": best_acc,\n",
    "        \"final_acc\": last_acc,\n",
    "        \"time\": total_time,\n",
    "        \"epochs\": epoch,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Per-seed experiment\n",
    "# ============================================\n",
    "\n",
    "def run_single_seed(seed, train_loader, test_loader, use_quantum=True):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # ---------------- RealNet ----------------\n",
    "    print(f\"\\n  Training RealNet (seed={seed})...\")\n",
    "    real_model = RealNet().to(device)\n",
    "    real_opt = torch.optim.Adam(real_model.parameters(), lr=1e-3)\n",
    "    results[\"Real\"] = train_with_early_stopping(\n",
    "        real_model, train_loader, test_loader, real_opt, device,\n",
    "        max_epochs=40, patience=8, name=\"Real\"\n",
    "    )\n",
    "    results[\"Real\"][\"params\"] = sum(p.numel() for p in real_model.parameters())\n",
    "\n",
    "    # ---------------- Freeze preprocessor ----------------\n",
    "    shared_preprocessor = real_model.preprocessor\n",
    "    for p in shared_preprocessor.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    print(f\"\\n  → Preprocessor frozen with \"\n",
    "          f\"{sum(p.numel() for p in shared_preprocessor.parameters())} params\")\n",
    "\n",
    "    # ---------------- QuatNet ----------------\n",
    "    print(f\"\\n  Training QuatNet with frozen preprocessor (seed={seed})...\")\n",
    "    quat_model = QuatNet().to(device)\n",
    "    quat_model.preprocessor = shared_preprocessor\n",
    "    quat_opt = torch.optim.Adam(quat_model.head.parameters(), lr=1e-3)\n",
    "    results[\"Quat\"] = train_with_early_stopping(\n",
    "        quat_model, train_loader, test_loader, quat_opt, device,\n",
    "        max_epochs=40, patience=8, name=\"Quat\"\n",
    "    )\n",
    "    results[\"Quat\"][\"params\"] = sum(p.numel() for p in quat_model.parameters()\n",
    "                                    if p.requires_grad)\n",
    "    results[\"Quat\"][\"total_params\"] = sum(p.numel() for p in quat_model.parameters())\n",
    "\n",
    "    # ---------------- QuantumNet (if available) ----------------\n",
    "    if use_quantum and PENNYLANE_AVAILABLE:\n",
    "        from torch.utils.data import DataLoader as TorchDataLoader\n",
    "\n",
    "        # Smaller batches for quantum models\n",
    "        quantum_train_loader = TorchDataLoader(\n",
    "            train_loader.dataset, batch_size=32, shuffle=True, num_workers=0\n",
    "        )\n",
    "        quantum_test_loader = TorchDataLoader(\n",
    "            test_loader.dataset, batch_size=64, shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "        # Copy frozen preprocessor to CPU\n",
    "        shared_preprocessor_cpu = SharedPreprocessor(784, 16)\n",
    "        shared_preprocessor_cpu.load_state_dict(shared_preprocessor.state_dict())\n",
    "        for p in shared_preprocessor_cpu.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # ---- Quantum no entanglement ----\n",
    "        print(f\"\\n  Training QuantumNet (NO entanglement, seed={seed}, {QUANTUM_DEVICE})...\")\n",
    "        qno_model = QuantumNet(use_entanglement=False)\n",
    "        qno_model.preprocessor = shared_preprocessor_cpu\n",
    "        qno_opt = torch.optim.Adam(qno_model.head.parameters(), lr=1e-3)\n",
    "        \n",
    "        # On GPU-accelerated lightning, allow much longer training with patience-based stopping.\n",
    "        # This lets the quantum model actually reach its plateau instead of hitting a hard epoch cap.\n",
    "        results[\"QNoEnt\"] = train_with_early_stopping(\n",
    "            qno_model, quantum_train_loader, quantum_test_loader,\n",
    "            qno_opt,\n",
    "            device=\"cpu\",          # quantum work still happens on GPU via PennyLane\n",
    "            max_epochs=200,        # was 30\n",
    "            patience=20,           # was 6\n",
    "            name=\"QuantumNoEnt\"\n",
    "        )\n",
    "        results[\"QNoEnt\"][\"params\"] = sum(p.numel() for p in qno_model.parameters()\n",
    "                                          if p.requires_grad)\n",
    "        results[\"QNoEnt\"][\"total_params\"] = sum(p.numel() for p in qno_model.parameters())\n",
    "        \n",
    "        # ---- Quantum with entanglement ----\n",
    "        print(f\"\\n  Training QuantumNet (WITH entanglement, seed={seed}, {QUANTUM_DEVICE})...\")\n",
    "        qent_model = QuantumNet(use_entanglement=True)\n",
    "        qent_model.preprocessor = shared_preprocessor_cpu\n",
    "        qent_opt = torch.optim.Adam(qent_model.head.parameters(), lr=1e-3)\n",
    "        \n",
    "        results[\"QEnt\"] = train_with_early_stopping(\n",
    "            qent_model, quantum_train_loader, quantum_test_loader,\n",
    "            qent_opt,\n",
    "            device=\"cpu\",          # same logic: PennyLane uses GPU internally\n",
    "            max_epochs=200,        # was 30\n",
    "            patience=20,           # was 6\n",
    "            name=\"QuantumEnt\"\n",
    "        )\n",
    "        results[\"QEnt\"][\"params\"] = sum(p.numel() for p in qent_model.parameters()\n",
    "                                        if p.requires_grad)\n",
    "        results[\"QEnt\"][\"total_params\"] = sum(p.numel() for p in qent_model.parameters())\n",
    "\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Main Experiment\n",
    "# ============================================\n",
    "\n",
    "def stratified_sample(dataset, n_samples_per_class):\n",
    "    \"\"\"\n",
    "    Create a stratified sample with n_samples_per_class from each class.\n",
    "    Maintains class balance.\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # Group indices by class\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    # Sample from each class\n",
    "    sampled_indices = []\n",
    "    for class_label in sorted(class_indices.keys()):\n",
    "        indices = class_indices[class_label]\n",
    "        # Use fixed random seed for reproducibility\n",
    "        rng = np.random.RandomState(42)\n",
    "        selected = rng.choice(indices, size=min(n_samples_per_class, len(indices)), \n",
    "                             replace=False)\n",
    "        sampled_indices.extend(selected)\n",
    "    \n",
    "    return sampled_indices\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"CLEAN SU(2) COMPARISON: Real vs Quaternion vs Quantum (LIGHTNING)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nExperimental Design:\")\n",
    "    print(\"  • Dataset: MNIST (28×28 grayscale)\")\n",
    "    print(\"  • Stratified sampling: 15K train (1,500/class), 3K test (300/class)\")\n",
    "    print(\"    - Rationale: Models have ~10-15K parameters; 60K samples unnecessary\")\n",
    "    print(\"    - Enables 4-6x faster quantum training while maintaining valid comparison\")\n",
    "    print(\"    - All models train on identical stratified samples\")\n",
    "    print(\"  • Shared preprocessor: 784 → 16 features\")\n",
    "    print(\"    - Trained with RealNet, then frozen\")\n",
    "    print(\"    - Reused (frozen) for Quat and Quantum heads\")\n",
    "    print(\"  • Heads on identical 16-D frozen features:\")\n",
    "    print(\"    - Real head: 16 → 64 → 10 (standard MLP)\")\n",
    "    print(\"    - Quaternion head: 4 quats → 16 quats → 10 quats → 10\")\n",
    "    print(\"    - Quantum head (no ent): 4 qubits, 3 layers → 10\")\n",
    "    print(\"    - Quantum head (entangled): 4 qubits, 3 layers + CNOT ring → 10\")\n",
    "    print(f\"\\nQuantum device: {QUANTUM_DEVICE}\")\n",
    "    if \"lightning.gpu\" in str(QUANTUM_DEVICE):\n",
    "        print(\"  Expected quantum training time: ~30-45 min per seed\")\n",
    "    elif \"lightning\" in str(QUANTUM_DEVICE):\n",
    "        print(\"  Expected quantum training time: ~1-2 hours per seed\")\n",
    "    else:\n",
    "        print(\"  Expected quantum training time: ~6-8 hours per seed\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    # Load full datasets\n",
    "    full_train_ds = datasets.MNIST(root=\"./data\", train=True,\n",
    "                                   download=True, transform=transform)\n",
    "    full_test_ds = datasets.MNIST(root=\"./data\", train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "    # Create stratified samples\n",
    "    print(\"\\nCreating stratified samples...\")\n",
    "    train_indices = stratified_sample(full_train_ds, n_samples_per_class=1500)  # 15K total\n",
    "    test_indices = stratified_sample(full_test_ds, n_samples_per_class=300)     # 3K total\n",
    "    \n",
    "    from torch.utils.data import Subset\n",
    "    train_ds = Subset(full_train_ds, train_indices)\n",
    "    test_ds = Subset(full_test_ds, test_indices)\n",
    "    \n",
    "    print(f\"  Train samples: {len(train_ds)} (stratified, 1500 per class)\")\n",
    "    print(f\"  Test samples:  {len(test_ds)} (stratified, 300 per class)\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128,\n",
    "                              shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_ds, batch_size=256,\n",
    "                             shuffle=False, num_workers=0)\n",
    "\n",
    "    seeds = [42, 123, 456]\n",
    "    all_results = {\n",
    "        \"Real\": [],\n",
    "        \"Quat\": [],\n",
    "        \"QNoEnt\": [],\n",
    "        \"QEnt\": [],\n",
    "    }\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"SEED {seed}\")\n",
    "        print(\"=\" * 70)\n",
    "        seed_results = run_single_seed(seed, train_loader, test_loader, \n",
    "                                      use_quantum=PENNYLANE_AVAILABLE)\n",
    "\n",
    "        for key in all_results.keys():\n",
    "            if key in seed_results:\n",
    "                all_results[key].append(seed_results[key])\n",
    "\n",
    "    # Aggregate\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"AGGREGATED RESULTS (mean ± std over seeds)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    def summarize(name):\n",
    "        if len(all_results[name]) == 0:\n",
    "            return\n",
    "        accs = [r[\"best_acc\"] for r in all_results[name]]\n",
    "        times = [r[\"time\"] for r in all_results[name]]\n",
    "        epochs = [r[\"epochs\"] for r in all_results[name]]\n",
    "\n",
    "        if name == \"Real\":\n",
    "            params = all_results[name][0][\"params\"]\n",
    "            param_str = f\"{params:,}\"\n",
    "        else:\n",
    "            trainable = all_results[name][0][\"params\"]\n",
    "            total = all_results[name][0][\"total_params\"]\n",
    "            param_str = f\"{trainable:,} trainable (head), {total:,} total\"\n",
    "\n",
    "        print(f\"\\n{name:8s}:\")\n",
    "        print(f\"  Accuracy:   {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "        print(f\"  Time:       {np.mean(times):.1f}s (avg)\")\n",
    "        print(f\"  Epochs:     {np.mean(epochs):.1f} (avg)\")\n",
    "        print(f\"  Parameters: {param_str}\")\n",
    "\n",
    "    for name in [\"Real\", \"Quat\", \"QNoEnt\", \"QEnt\"]:\n",
    "        summarize(name)\n",
    "\n",
    "    # Comparative analysis\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"COMPARATIVE ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    real_accs = [r[\"best_acc\"] for r in all_results[\"Real\"]]\n",
    "    quat_accs = [r[\"best_acc\"] for r in all_results[\"Quat\"]]\n",
    "    \n",
    "    if all_results[\"QNoEnt\"]:\n",
    "        qno_accs = [r[\"best_acc\"] for r in all_results[\"QNoEnt\"]]\n",
    "        qent_accs = [r[\"best_acc\"] for r in all_results[\"QEnt\"]]\n",
    "\n",
    "        def pct_gap(a, b):\n",
    "            return (np.mean(a) - np.mean(b)) * 100.0\n",
    "\n",
    "        print(f\"\\n1. Quat vs Real:\")\n",
    "        print(f\"   Gap: {pct_gap(real_accs, quat_accs):.2f} percentage points\")\n",
    "        print(f\"   Quat captures {np.mean(quat_accs)/np.mean(real_accs)*100:.1f}% of Real performance\")\n",
    "\n",
    "        print(f\"\\n2. Quantum (no ent) vs Real:\")\n",
    "        print(f\"   Gap: {pct_gap(real_accs, qno_accs):.2f} percentage points\")\n",
    "        print(f\"   QNoEnt captures {np.mean(qno_accs)/np.mean(real_accs)*100:.1f}% of Real performance\")\n",
    "\n",
    "        print(f\"\\n3. Quantum (ent) vs Real:\")\n",
    "        print(f\"   Gap: {pct_gap(real_accs, qent_accs):.2f} percentage points\")\n",
    "        print(f\"   QEnt captures {np.mean(qent_accs)/np.mean(real_accs)*100:.1f}% of Real performance\")\n",
    "\n",
    "        print(f\"\\n4. Quantum (ent) vs Quantum (no ent):\")\n",
    "        print(f\"   Gap: {pct_gap(qno_accs, qent_accs):.2f} percentage points\")\n",
    "        if np.mean(qent_accs) > np.mean(qno_accs):\n",
    "            print(\"   → Entanglement improves performance.\")\n",
    "        else:\n",
    "            print(\"   → Entanglement does not improve performance here.\")\n",
    "\n",
    "        print(f\"\\n5. Quantum vs Quaternion:\")\n",
    "        print(f\"   Gap (Quat - QNoEnt): {pct_gap(quat_accs, qno_accs):.2f} points\")\n",
    "        print(f\"   Gap (Quat - QEnt):   {pct_gap(quat_accs, qent_accs):.2f} points\")\n",
    "    else:\n",
    "        print(\"\\nQuantum models not trained (PennyLane not available)\")\n",
    "        print(\"Only Real vs Quat comparison available:\")\n",
    "        def pct_gap(a, b):\n",
    "            return (np.mean(a) - np.mean(b)) * 100.0\n",
    "        print(f\"   Gap: {pct_gap(real_accs, quat_accs):.2f} percentage points\")\n",
    "        print(f\"   Quat captures {np.mean(quat_accs)/np.mean(real_accs)*100:.1f}% of Real performance\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"KEY INTERPRETATION HINTS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Check:\")\n",
    "    print(\"  • How close Quat is to Real (does classical SU(2) keep up with MLP?).\")\n",
    "    if all_results[\"QNoEnt\"]:\n",
    "        print(\"  • Whether QNoEnt ≈ Quat (quantum SU(2) w/o entanglement vs quaternion).\")\n",
    "        print(\"  • Whether QEnt > QNoEnt (empirical value of entanglement on MNIST).\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59110581-a0ef-4b42-ac34-ba8cfc5c98ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
